{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TODOs ###\n",
    "# DONE: Implement Semantic Ranking\n",
    "# TODOs: Commonsense Query and Concept Expansion: Topics, Concepts, Synonyms\n",
    "# TODOs: Targeted Retrieval with NLI over ADUs, Premises, Claims; discard non-ADUs\n",
    "\n",
    "# DONE: News Data\n",
    "# DONE: Add Concepts\n",
    "# DONE: Cosine Semantic Search\n",
    "# DONE: Prior Pre-processing, tokenization and sentence segmentation to speed processing\n",
    "# TODOs: Domain Restrict. Polarising social and political debate (Class labelling) only for higher-quality argument-knowledge set.\n",
    "# TODOs: News, Political, Sociology and 'Good', 'Positive' counter-evidence Knowledge Base.\n",
    "# TODOs: Bag of Topics Modelling\n",
    "# TODOs: Implement as a Class\n",
    "\n",
    "# TODOs: Keyphrase Selection\n",
    "# DONE: Manage Duplicate Keywords\n",
    "# DONE: Sentential Ranking\n",
    "# DONE: Include Topic Label\n",
    "# DONE: Include Concept Label\n",
    "# DONE: Add News\n",
    "# TODOs: Targeted Retreival with Semantic Graphs\n",
    "# TODOs: Target Argumentative Content Only\n",
    "# TODOs: Targeted Argument Content: Adus + Extractive Summary\n",
    "# TODOs: Query Expansion\n",
    "# TODOs: Multi-Field Search\n",
    "# TODOs: Additional News and Knowledge Sources"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### INIT LOGGING ###\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"ARGUMENT-EXTRACTOR\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### INIT KNOWLEDGEBASE ###\n",
    "from src.utils.elastic_db import ElasticDB\n",
    "\n",
    "PORT = \"http://localhost:9200\"\n",
    "db = ElasticDB(elastic_port=PORT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### NLP FUNCTIONS ###\n",
    "from src.utils.utils import tokeniser, sentences_segment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### ADU CLASSIFIER ###\n",
    "# import os\n",
    "# path = \"/Users/joshua.sheppard/PycharmProjects/countaBot/\"\n",
    "# os.chdir(path)\n",
    "\n",
    "from src.detection.adu_classifier import predict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD DATASETS ###\n",
    "import json\n",
    "import os\n",
    "\n",
    "root = \"/Users/joshua.sheppard/PycharmProjects/countaBot\"\n",
    "os.chdir(root)\n",
    "\n",
    "args = [json.loads(ln) for ln in open(\"./src/data/processed/cmv_processed.jsonl\")]\n",
    "mined_args = [json.loads(ln) for ln in open(\"./src/data/processed/cmv_argument_extraction.jsonl\")]\n",
    "topics = [json.loads(ln) for ln in open(\"./src/data/processed/argument_topic_concept.jsonl\")]\n",
    "concepts = [json.loads(ln) for ln in open(\"./src/data/processed/argument_concept.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"ARGS:\", len(args), \" MINED-ARGS:\",  len(mined_args), \" TOPICS:\", len(topics), \" CONCEPTS: \", len(concepts))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSPECT SUBJECT ARG ###\n",
    "import random\n",
    "_ = random.randint(0, len(mined_args))\n",
    "\n",
    "arg = \" \".join(i[\"sentence\"] for i in mined_args[_][\"argument\"])\n",
    "claim = mined_args[_][\"claim\"][\"sentence\"]\n",
    "\n",
    "#print(mined_args[_])\n",
    "print(_, \"\\n\")\n",
    "print(\"CLAIM: \", claim, \"\\n\")\n",
    "print(\"ARG: \", arg, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### KEYPHRASE EXTRACTORS ###\n",
    "from src.utils.keyphrase_extraction import yake_extract_keyphrase, summa_extract_keyphrase\n",
    "import keybert\n",
    "\n",
    "test = \"Brazil's minimum income has increasingly been accepted.\"\n",
    "ev_kp = yake_extract_keyphrase(test)\n",
    "ev_kp_ = summa_extract_keyphrase(test)\n",
    "\n",
    "test_2 = \" \"\n",
    "ev_kp_2 = yake_extract_keyphrase(test_2)\n",
    "ev_kp_2_ = summa_extract_keyphrase(test_2)\n",
    "\n",
    "print(ev_kp)\n",
    "print(ev_kp_)\n",
    "\n",
    "# Assert can Handel Blanks\n",
    "print(ev_kp_2)\n",
    "print(ev_kp_2_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import multiprocessing\n",
    "from src.detection.stance_classifier import sentence_stance, compare_stance\n",
    "from src.detection.stance_classifier import sentence_stance\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Disable Huggingface Logging\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "topic_ids = [json.loads(ln)[\"id\"] for ln in open(\"./src/data/processed/argument_topic_concept.jsonl\")]\n",
    "concept_ids = [json.loads(ln)[\"id\"] for ln in open(\"./src/data/processed/argument_concept.jsonl\")]\n",
    "\n",
    "def clean(phrase):\n",
    "    return re.sub(r\"[,.;@#?!&$]+\\ *\", \" \", phrase)\n",
    "\n",
    "def get_notion(notions_ids, notions_lst, arg_id, label):\n",
    "    notion_id = notions_ids.index(arg_id)\n",
    "    notion = notions_lst[notion_id][label]\n",
    "    return str(notion) if notion else None\n",
    "\n",
    "### RETRIEVER ###\n",
    "db = db\n",
    "queries = []\n",
    "retrieved_ev = []\n",
    "\n",
    "# TODOs: Argumentative Sentence\n",
    "# TODOs: Query Expansion\n",
    "def search(mined, type=\"tgt_counter\", l=10):\n",
    "    id_ = mined[\"id\"]\n",
    "    claim = arg[\"claim\"]\n",
    "\n",
    "    topic = get_notion(topic_ids, topics, id_, \"topic_label\")\n",
    "    concept = get_notion(concept_ids, concepts, id_, \"concept_label\")\n",
    "\n",
    "    retrieved = []\n",
    "\n",
    "    adu_count = 0\n",
    "    targeted_response = []\n",
    "    for adu in mined[type]:\n",
    "\n",
    "        sentence = adu[\"sentence\"]\n",
    "        # if predict(sentence) != \"premise\":\n",
    "        #     # Count ADUs for reference\n",
    "        #     continue\n",
    "\n",
    "        # TODOs: Check this isn't overriding continue\n",
    "        adu_count += 1\n",
    "\n",
    "        #kp = extract_keyphrase(sentence)\n",
    "        kp = list(set(adu[\"kp\"]))\n",
    "\n",
    "        # TODOs: Common-sense Query Expansion\n",
    "        query = []\n",
    "        query.extend(kp)\n",
    "\n",
    "        # Ensure topics and concepts are unpacked (extended) into query list, as lists, else string will unpack 'l', 'i', 'k', 'e', 't'\n",
    "        query.extend([topic]) if topic else query\n",
    "        query.extend([concept]) if concept else query\n",
    "        query = list(set(query))\n",
    "\n",
    "        # Note: Now query becomes a string - be careful\n",
    "        query = \", \".join(i for i in query)\n",
    "        # print(query)\n",
    "\n",
    "        search = [(i[\"_source\"][\"document\"][\"source\"], i[\"_source\"][\"document\"][\"text\"]) for i in db.search(query_=query, k=l)]\n",
    "\n",
    "        source = [i[0] for i in search]\n",
    "        evidence = [i[1] for i in search]\n",
    "\n",
    "        #print(\"query\", query)\n",
    "        merged = \", \".join(i for i in evidence)\n",
    "        ev_kp = list(set(yake_extract_keyphrase(merged)))\n",
    "\n",
    "        retrieved.append({\"passages\": evidence, \"kp\": [clean(i) for i in ev_kp], \"source\": source})\n",
    "\n",
    "        targeted_response.append({\"sentence\": adu[\"sentence\"], \"selected_keyphrases\": []})\n",
    "\n",
    "    # TODOs: Implement yield without storing list\n",
    "    return ({\n",
    "        \"id\": id_,\n",
    "        \"claim\": claim,\n",
    "        \"argument\": mined[\"argument\"],\n",
    "        \"tgt_counter\": [i for i in targeted_response],\n",
    "        \"retrieved\": [i for i in retrieved],\n",
    "        \"adu_count\": adu_count\n",
    "    })\n",
    "\n",
    "# SINGLE ARGUMENT INSPECT\n",
    "# SAMPLE = unique_args[0]\n",
    "# results = search(SAMPLE)\n",
    "\n",
    "# tic = time.time()\n",
    "# SAMPLE = mined_args\n",
    "\n",
    "# retrieved_ev = []\n",
    "# with multiprocessing.Pool(8) as pool:\n",
    "#     with tqdm(total=(len(SAMPLE)), position=0, leave=True) as pbar:\n",
    "#         for arg in SAMPLE:\n",
    "#             retrieved_ev.append(search(arg))\n",
    "#             pbar.update()\n",
    "#     toc = time.time()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retrieved_ev[4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "retrieved_ev_ = copy.deepcopy(retrieved_ev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "duration = toc - tic\n",
    "print(\"TIME\", duration)\n",
    "retrieved_ev[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(retrieved_ev)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODOs: Check Counter, Argument params pre-proccess\n",
    "# TODOs: Process Argument pairs fully; Constrain at train time\n",
    "\n",
    "_ = random.randint(0, len(mined_args))\n",
    "\n",
    "# NOTE: ADU Opinion Classifier reduces returned argument response. This is ok.\n",
    "print(\"Argument\", len(retrieved_ev[_][\"argument\"]), \"Retrieved\", len(retrieved_ev[70][\"retrieved\"]))\n",
    "\n",
    "# NOTE: ADU Opinion Classifier reduces returned argument response. This is ok.\n",
    "print(\"Counter\", len(retrieved_ev[_][\"tgt_counter\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# file_name = \"cmv_retrieved\"\n",
    "# fout = open(f\"./src/data/{file_name}.jsonl\", \"w\")\n",
    "#\n",
    "# #with fout:\n",
    "#     fout.write(json.dumps(retrieved_ev))\n",
    "#\n",
    "# logger.info(f\"[{len(retrieved_ev)} Data Stored as {file_name}.jsonl]\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### REVIEW ###\n",
    "# import os\n",
    "# print(os.getcwd())\n",
    "\n",
    "retrieved_ev_ = [json.loads(ln) for ln in open(\"./src/data/cmv_retrieved.jsonl\", \"r\")][0]\n",
    "\n",
    "_ = random.randint(0, len(review))\n",
    "print(retrieved_ev_[_][\"argument\"], \"\\n\")\n",
    "print(retrieved_ev_[_][\"retrieved\"], \"\\n\")\n",
    "print(retrieved_ev_[_][\"tgt_counter\"], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(retrieved_ev_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# TODOs: Discard equivalent stance, per sentence\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def cosine_similarity_(sentences):\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True, show_progress_bar=False)\n",
    "\n",
    "    cos = torch.nn.CosineSimilarity()\n",
    "    scores = cos(embeddings[0], embeddings[1:])\n",
    "\n",
    "    scored = []\n",
    "    retrieved_sentences = sentences[1:]\n",
    "    for sent, similarity in zip(retrieved_sentences, scores):\n",
    "        scored.append((sent, similarity.numpy().item()))\n",
    "\n",
    "    return scored\n",
    "\n",
    "def rank_passages(ev, k=3):\n",
    "    \"\"\" return ranked passages using cosine-similarity between the input-argument and the retrieved passages\n",
    "        k determines the number of returned passages from the originally retrieved set.\n",
    "    \"\"\"\n",
    "    #adus = [i[\"sentence\"] for i in ev[\"argument\"]]\n",
    "    # Compare TGT with RETREIVED\n",
    "    adus = [i[\"sentence\"] for i in ev[\"tgt_counter\"]]\n",
    "    retrieved_passages = [i[\"passages\"] for i in ev[\"retrieved\"]]\n",
    "\n",
    "    #print(retrieved_passages)\n",
    "\n",
    "    # Merge\n",
    "    # Output 1 x merged sentences object per ADU sentence, with k collected passages as a list of sentences\n",
    "    merged_passages = []\n",
    "    for passages in retrieved_passages:\n",
    "        merged_sents = []\n",
    "        # Iterate n x sentences for each k=5 retrieved passages\n",
    "        for passage in passages:\n",
    "            # Segment as a list of sentences\n",
    "            sents = sentences_segment(passage)\n",
    "            # Add sentences to merged_sentences object\n",
    "            merged_sents.extend(sents)\n",
    "\n",
    "        # Store merged sentence object for each ADU\n",
    "        merged_passages.append(merged_sents)\n",
    "\n",
    "    rank_retrieved = []\n",
    "    # Rank n x merged sentences for each 1 x ADU\n",
    "    for adu, merged in zip(adus, merged_passages):\n",
    "        scored = []\n",
    "        sentences = [adu]\n",
    "        sentences.extend(merged)\n",
    "        scored = cosine_similarity_(sentences)\n",
    "\n",
    "        ranked_sents = sorted(scored, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Select top-k sentences\n",
    "        ranked_sents = ranked_sents[0:k]\n",
    "\n",
    "        merged = \", \".join(i[0] for i in ranked_sents)\n",
    "        merged_kp = yake_extract_keyphrase(merged)\n",
    "        rank_retrieved.append({\"ranked_passages\": merged, \"kp\": merged_kp})\n",
    "\n",
    "    #print(\"\\n RANKED\", rank_retrieved)\n",
    "    return rank_retrieved\n",
    "\n",
    "# TODOs: Join passages and sentence rank\n",
    "### SCORE COSINE SIMILARITY ###\n",
    "tic = time.time()\n",
    "retrieved_ranked = copy.deepcopy(retrieved_ev_)\n",
    "counta = 0\n",
    "with tqdm(total=(len(retrieved_ev_)), position=0, leave=True) as pbar:\n",
    "    for i in range(0, len(retrieved_ev_)):\n",
    "        counta += 1\n",
    "        retrieved_ranked[i][\"retrieved\"] = [i for i in rank_passages(retrieved_ev_[i])]\n",
    "        pbar.update()\n",
    "\n",
    "toc = time.time()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "retrieved_ranked_ = copy.deepcopy(retrieved_ranked)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subject = retrieved_ranked[2]\n",
    "\n",
    "for i in subject:\n",
    "    for _, j in zip(subject[\"tgt_counter\"], subject[\"retrieved\"]):\n",
    "        print(\"COUNTER: \", _, \"\\n\")\n",
    "        print(\"EVIDENCE: \",j, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "duration = toc - tic\n",
    "print(duration)\n",
    "len(retrieved_ranked)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# NOTE: Zipping retrieved evidence, args\n",
    "print(len(retrieved_ranked), len(retrieved_ev), len(args))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = random.randint(0, len(retrieved_ev))\n",
    "retrieved_ranked[_]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = \"cmv_rr_\"\n",
    "fout = open(f\"./src/data/processed/{file_name}.jsonl\", \"w\")\n",
    "\n",
    "# Deep_copies\n",
    "rr = copy.deepcopy(retrieved_ranked)\n",
    "\n",
    "with tqdm(total=(len(rr))) as pbar:\n",
    "    with fout:\n",
    "        for ln in rr:\n",
    "            fout.write(json.dumps(ln))\n",
    "            pbar.update()\n",
    "\n",
    "logger.info(f\"[{len(rr)} Data Stored as {file_name}.jsonl]\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### INSPECT OUTPUT ###\n",
    "rr_ = [json.loads(ln) for ln in open(\"./src/data/processed/cmv_rr.jsonl\", \"r\")][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subject = rr_[random.randint(0, len(rr_))]\n",
    "\n",
    "print(\"CLAIM: \", subject[\"claim\"][\"sentence\"])\n",
    "print(\"===========================================\\n\")\n",
    "for i, j, k in zip(subject[\"argument\"], subject[\"tgt_counter\"], subject[\"retrieved\"]):\n",
    "    print(\"ARG: \", i[\"sentence\"], \"\\n\")\n",
    "    print(\"COUNTER: \", j[\"sentence\"], \"\\n\")\n",
    "    print(\"EVIDENCE: \", clean(k[\"ranked_passages\"]).lower(), \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DONE: Keyphrase Selection\n",
    "# TODOs: Full-run, arguments\n",
    "import copy\n",
    "\n",
    "### KEYPHRASE SELECTION OBJECT ###\n",
    "_rr = copy.deepcopy(rr_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "def clean(phrase):\n",
    "    return re.sub(r\"[,.;@#?!&$]+\\ *\", \" \", phrase)\n",
    "\n",
    "def cosine_similarity_(sentences):\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True, show_progress_bar=False)\n",
    "\n",
    "    cos = torch.nn.CosineSimilarity()\n",
    "    scores = cos(embeddings[0], embeddings[1:])\n",
    "\n",
    "    scored = []\n",
    "    retrieved_sentences = sentences[1:]\n",
    "    for sent, similarity in zip(retrieved_sentences, scores):\n",
    "        scored.append((sent, similarity.numpy().item()))\n",
    "\n",
    "    return scored\n",
    "\n",
    "def selected_keyphrases(arg):\n",
    "    kps = [_[\"kp\"] for _ in arg[\"retrieved\"]]\n",
    "    tgt_sentences = [_[\"sentence\"] for _ in arg[\"tgt_counter\"]]\n",
    "\n",
    "    selected_kps = []\n",
    "    for tgt, kp in zip(tgt_sentences, kps):\n",
    "        vectors = [tgt]\n",
    "        vectors.extend(kp)\n",
    "\n",
    "        similarity = cosine_similarity_(vectors)\n",
    "        #print(\"Before: \", [i[0] for i in similarity])\n",
    "        selected = [i[0] for i in similarity if i[1] > 0.2]\n",
    "\n",
    "        selected_kps.append(list(set(selected)))\n",
    "\n",
    "    for _, j in zip(arg[\"tgt_counter\"], selected_kps):\n",
    "        _[\"selected_keyphrases\"] = j"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### SELECTED KEYPHRASES ###\n",
    "import tqdm as tqdm\n",
    "\n",
    "SAMPLE = _rr\n",
    "with tqdm.tqdm_notebook(total=(SAMPLE), position=0, leave=True) as pbar:\n",
    "    for arg in SAMPLE:\n",
    "        selected_keyphrases(arg)\n",
    "        pbar.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_ = random.randint(0, 9)\n",
    "_rr[_][\"tgt_counter\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# WORK WITH DEEP COPIES\n",
    "\n",
    "def overlap_kp(string, sub):\n",
    "    count = start = 0\n",
    "    while True:\n",
    "        start = string.find(sub, start) + 1\n",
    "        if start > 0:\n",
    "            count+=1\n",
    "        else:\n",
    "            return count\n",
    "\n",
    "## WORKING, YET REPLACED WITH SIMILARITY ###\n",
    "\n",
    "# DONE: Similarity rank\n",
    "# DONE: Add Stopwords\n",
    "# stop = [i.strip() for i in open(\"./src/data/lexicon/stopwords.txt\")]\n",
    "# def selected_keyphrases(arg):\n",
    "#     kps = [_[\"kp\"] for _ in arg[\"retrieved\"]]\n",
    "#     tgt_sentences = [_[\"sentence\"] for _ in arg[\"tgt_counter\"]]\n",
    "#\n",
    "#     selected_kps = []\n",
    "#\n",
    "#     # Iterate per target sentence\n",
    "#     for tgt, kp in zip(tgt_sentences, kps):\n",
    "#         selected = []\n",
    "#\n",
    "#         for terms in kp:\n",
    "#             singletons = terms.split()\n",
    "#             for single in singletons:\n",
    "#                 if single in stop:\n",
    "#                     continue\n",
    "#                 if overlap_kp(tgt.lower(), single) > 0:\n",
    "#                     selected.append(terms)\n",
    "#\n",
    "#         selected_kps.append(list(set(selected)))\n",
    "#\n",
    "#     for _, j in zip(arg[\"tgt_counter\"], selected_kps):\n",
    "#         _[\"selected_keyphrases\"] = j"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b747fec5972a5a28202124dfae2950631b4721a6e18efe99aaae23c73408484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
