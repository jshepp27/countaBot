{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ZERO-SHOT CLASSIFICATION, TOPIC LABELLING ###\n",
    "\n",
    "# TODOs: Discovering Interpretable Topics by Leveraging Common Sense Knowledge (Facebook)\n",
    "# TODOs: https://towardsdatascience.com/zero-shot-text-classification-with-hugging-face-7f533ba83cd6\n",
    "# DONE: Extract args, ids for labelling\n",
    "# DONE: Get Labels\n",
    "# TODOs: NLI vs Semantic\n",
    "# TODOs: Zero-shot Classification ConceptNet (semantic extension)\n",
    "# TODOs: Expand: Concept Net synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### ASSERT WORKING DIRECTORY FOR IMPORTS ###\n",
    "import os\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### LOAD ###\n",
    "#args = [json.loads(ln) for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "arg_ids = [json.loads(ln)[\"id\"] for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "args = [json.loads(ln)[\"argument\"][\"argument\"] for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "claims = [json.loads(ln)[\"claim\"] for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "\n",
    "extracts = [json.loads(ln)[\"extract\"] for ln in open(\"../data/argument_extracts.jsonl\")]\n",
    "extract_ids = [json.loads(ln)[\"id\"] for ln in open(\"../data/argument_extracts.jsonl\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### SAMPLE ###\n",
    "_ = random.randint(0, len(args))\n",
    "args[_]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNIQUE ARGUMENTS ###\n",
    "corpus = set()\n",
    "idx = set()\n",
    "\n",
    "for j, k in zip(args, arg_ids):\n",
    "    corpus.add((j, k))\n",
    "\n",
    "corpus = list(corpus)\n",
    "type(corpus), len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### UNIQUE EXTRACTS LIST ###\n",
    "extract_corpus = set()\n",
    "idx = set()\n",
    "\n",
    "for j, k in zip(extracts, extract_ids):\n",
    "    extract_corpus.add((j, k))\n",
    "\n",
    "extract_corpus"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### FORM NEW ARGUMENT-SET ###\n",
    "\n",
    "# TODO: Return Domain Restricted\n",
    "args = [json.loads(ln) for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "extracts = [json.loads(ln) for ln in open(\"../data/argument_extracts.jsonl\")]\n",
    "arg_ids = [json.loads(ln)[\"id\"] for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "\n",
    "def get_arg(id_):\n",
    "    if id_ in arg_ids:\n",
    "        arg_location = arg_ids.index(id_)\n",
    "        arg = args[arg_location]\n",
    "        return arg\n",
    "\n",
    "    else: return None\n",
    "\n",
    "args_w_extract = []\n",
    "for i in extracts:\n",
    "    extract_id = i[\"id\"]\n",
    "\n",
    "    arg = get_arg(extract_id)\n",
    "    arg[\"extract\"] = i[\"extract\"]\n",
    "\n",
    "    args_w_extract.append(arg)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "extracts = [json.loads(ln) for ln in open(\"../data/argument_extracts.jsonl\")]\n",
    "\n",
    "extract_w_claims = []\n",
    "for i in extracts:\n",
    "    extract = i[\"extract\"]\n",
    "    extract_id = i[\"id\"]\n",
    "\n",
    "    i[\"claim\"] = get_arg(extract_id)\n",
    "\n",
    "    extract_w_claims.append(extract)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### UNIQUE CLAIMS ###\n",
    "# claim_corpus = set()\n",
    "# idx = set()\n",
    "#\n",
    "# for j, k in zip(claims, ids):\n",
    "#     claim_corpus.add((j, k))\n",
    "#\n",
    "# claim_corpus = list(claim_corpus)\n",
    "# type(claim_corpus), len(claim_corpus)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMMON-SENSE POLARISED TOPIC LABELS ###\n",
    "import re\n",
    "def clean(clean):\n",
    "    clean = re.sub(r\"\\n\", \"\", clean)\n",
    "    clean = re.sub(r'(?<=[a-z])\\'(?=[a-z])', '', clean)\n",
    "    clean = re.sub('([^a-zA-Z\\s.!?])', \"\", clean)\n",
    "    clean = re.sub('\\s+', ' ', clean)\n",
    "\n",
    "    clean = re.sub(r\"www\\S+\", \"\", clean)\n",
    "    return clean.strip().lower()\n",
    "\n",
    "#TODOs: Prune and Add CauseNet Topics\n",
    "controversial_topics = [clean(ln) for ln in open(\"../data/concepts/wiki_controversial_topics.txt\")]\n",
    "debate_topics = [clean(ln) for ln in open(\"../data/concepts/IBM_debate_topics_I.txt\")]\n",
    "debate_topics_ = [clean(ln) for ln in open(\"../data/concepts/IBM_debate_topics_II.txt\")]\n",
    "arg_kb_20 = [clean(ln) for ln in open(\"../data/concepts/argkb_20_topics.txt\")]\n",
    "wiki_race = [clean(ln) for ln in open(\"../data/concepts/wiki_racism_related.txt\")]\n",
    "wiki_ideologies = [clean(ln) for ln in open(\"../data/concepts/wiki_political_ideologies.txt\")]\n",
    "\n",
    "concepts = [clean(ln) for ln in open(\"../data/concepts/cause_concepts.txt\")]\n",
    "\n",
    "topics = []\n",
    "topics.extend(controversial_topics)\n",
    "topics.extend(debate_topics)\n",
    "# topics.extend(debate_topics_)\n",
    "topics.extend(wiki_ideologies)\n",
    "# topics.extend(arg_kb_20)\n",
    "topics.extend(wiki_race)\n",
    "\n",
    "len(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Semantic-Search, Cosine Similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "def semantic_search(corpus, query, threshold=0.30):\n",
    "    # Construct Corpus set\n",
    "    corpus_, id_ = zip(*corpus)\n",
    "    corpus_ = list(corpus_)\n",
    "    id_ = list(id_)\n",
    "\n",
    "    # Embed the Corpus\n",
    "    corpus_embeddings = embedder.encode(corpus_, convert_to_tensor=True)\n",
    "\n",
    "    # Construct Query-Label set\n",
    "    queries = set(query)\n",
    "\n",
    "    mapped_dict = {}\n",
    "    for i in range(0, len(id_)):\n",
    "        mapped_dict[id_[i]] = {\"argument\": corpus_[i], \"label\": []}\n",
    "\n",
    "    # Return top k=1 argument for each Label via Cosine Similarity\n",
    "    top_k = min(1, len(corpus_))\n",
    "\n",
    "    with tqdm(total=len(queries)) as pbar:\n",
    "        for query in queries:\n",
    "            query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "            cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "            top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "            for score, idx in zip(top_results[0], top_results[1]):\n",
    "                # 'Empirical' threshold\n",
    "                if score >= threshold:\n",
    "                    # Append Label\n",
    "                    #mapped_dict[id_][\"argument\"] = corpus_[idx]\n",
    "                    # Note: Can use the same idx index\n",
    "                    mapped_dict[id_[idx]][\"label\"] = query.lower()\n",
    "\n",
    "                #else: mapped_dict[id_][\"label\"] = \"None\"\n",
    "\n",
    "            pbar.update()\n",
    "\n",
    "    return mapped_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### EXTRACT LABELLED INSTANCES ###\n",
    "def extract_labelled(dict_):\n",
    "    res = []\n",
    "    for i in dict_.items():\n",
    "        j, k = i\n",
    "\n",
    "        if k[\"label\"] != []:\n",
    "            res.append({\"id\": i[0], \"argument\": k[\"argument\"], \"label\": k[\"label\"]})\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODOs: Reverse the Query\n",
    "#sample = corpus[0:100]\n",
    "\n",
    "### LABELLING: CONTROVERSIAL TOPICS ###\n",
    "extract_topics = semantic_search(corpus=extract_corpus, query=topics, threshold=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(extract_topics), len(extract_labelled(extract_topics)))\n",
    "extract_topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# print(len(arg_topics), len(corpus))\n",
    "# print(len(arg_topics), len(extract_labelled(arg_topics)))\n",
    "# arg_topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODOs: Reverse the Query\n",
    "#sample = corpus[0:100]\n",
    "\n",
    "### LABELLING: CONTROVERSIAL TOPICS ###\n",
    "claim_topics = semantic_search(corpus=claim_corpus, query=topics, threshold=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(claim_topics), len(claim_corpus))\n",
    "print(len(arg_topics), len(extract_labelled(claim_topics)))\n",
    "arg_topics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### LABELLING: CONCEPTS ###\n",
    "arg_concepts = semantic_search(corpus=corpus, query=concepts)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(arg_concepts), len(extract_labelled(arg_concepts))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### STORE TOPIC LABELS CONCEPTS AND LABELS ###\n",
    "fout = open(\"../data/argument_topic_concept.jsonl\", \"w\")\n",
    "\n",
    "for j, k in arg_topics.items():\n",
    "    fout.write(json.dumps({\n",
    "        \"id\": j,\n",
    "        \"argument\": k[\"argument\"],\n",
    "        \"topic_label\": k[\"label\"],\n",
    "        #\"concept_label\": k[\"label\"]\n",
    "    }))\n",
    "    fout.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### STORE CONCEPT LABELS CONCEPTS AND LABELS ###\n",
    "fout = open(\"../data/argument_concepts.jsonl\", \"w\")\n",
    "\n",
    "for j, k in arg_concepts.items():\n",
    "    fout.write(json.dumps({\n",
    "        \"id\": j,\n",
    "        \"argument\": k[\"argument\"],\n",
    "        \"concept_label\": k[\"label\"],\n",
    "    }))\n",
    "    fout.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for j, k in arg_topics.items():\n",
    "    if k[\"argument\"] == \"\":\n",
    "        print(\"blanks\", j)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "arg_concepts"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### DOMAIN RESTRICTED ###\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ### QUERY EXPANSION ###\n",
    "#\n",
    "# # TODOs: Query Expansions [TypeOf, SimilarTerms, CanBe]\n",
    "# # https://github.com/fitosegrera/python-conceptnet/blob/master/ConceptNet.py\n",
    "# import json\n",
    "# import urllib\n",
    "#\n",
    "# URL = \"http://api.conceptnet.io/\"\n",
    "#\n",
    "# # TODOs: Review. Similarity.\n",
    "# class ConceptNet:\n",
    "#\n",
    "#     def __init__(self, api, l):\n",
    "#         self.api = api\n",
    "#         self.l = l\n",
    "#\n",
    "#     def search(self, lang, term):\n",
    "#         url_to_search = self.api + \"c/\" + lang + \"/\" + term\n",
    "#         data = urllib.request.urlopen(url_to_search)\n",
    "#         json_data = json.load(data)\n",
    "#         for i in json_data[\"edges\"]:\n",
    "#             print(\"----------------\")\n",
    "#             print(i[\"end\"])\n",
    "#             print(\"relation:\", i[\"rel\"])\n",
    "#             print(i[\"surfaceEnd\"])\n",
    "#             print(i[\"surfaceStart\"])\n",
    "#             print(\"weight:\", i[\"weight\"])\n",
    "#\n",
    "#         return json_data\n",
    "#\n",
    "#     def get_relation(self, rel, concept):\n",
    "#         url_to_search = self.api + f\"search?node=/c/en/{concept}&rel=/r/{rel}\"\n",
    "#         data = urllib.request.urlopen(url_to_search)\n",
    "#         obj_ = json.load(data)\n",
    "#\n",
    "#         labels = set()\n",
    "#         for _ in obj_[\"edges\"]:\n",
    "#             labels.add((_[\"end\"][\"label\"], _[\"weight\"]))\n",
    "#\n",
    "#         return labels\n",
    "#\n",
    "#     def get_similar(self, concept):\n",
    "#         res = []\n",
    "#         rels = [\"Synonym\", \"SimilarTo\"]\n",
    "#         for _ in rels:\n",
    "#             res.extend(self.get_relation(_, concept))\n",
    "#\n",
    "#         return sorted(res, key=lambda x: x[1], reverse=True)[:self.l]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# concept_net = ConceptNet(api=URL, l=3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### CONCEPT NET ###\n",
    "# from src.utils_.concept_net_expansion import ConceptNet\n",
    "# URL = \"http://api.conceptnet.io/\"\n",
    "#\n",
    "# concept_net = ConceptNet(URL, l=3)\n",
    "# expansion_term = \"carriage\"\n",
    "#\n",
    "# test_concept = concept_net.get_similar(expansion_term)\n",
    "# test_concept"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### WORDNET ###\n",
    "# from src.utils_.word_net_expansion import expand_query\n",
    "#\n",
    "# test_wn = expand_query(expansion_term)\n",
    "# test_wn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### EXTRACT LABELLED INSTANCES ###\n",
    "# def extract_labelled(dict_):\n",
    "#     res = []\n",
    "#     for i in dict_.items():\n",
    "#         j, k = i\n",
    "#\n",
    "#         if k[\"label\"] != \"None\":\n",
    "#             res.append({\"id\": i[0], \"argument\": k[\"argument\"], \"label\": k[\"label\"]})\n",
    "#     return res\n",
    "\n",
    "# args_topic_labelled = extract_labelled(arg_topics)\n",
    "# print(len(args_topic_labelled))\n",
    "#\n",
    "# args_topic_labelled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# args_topic_labelled = extract_labelled(arg_topics)\n",
    "# print(len(args_topic_labelled))\n",
    "#\n",
    "# args_topic_labelled"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b747fec5972a5a28202124dfae2950631b4721a6e18efe99aaae23c73408484"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
