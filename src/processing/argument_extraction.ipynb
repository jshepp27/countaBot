{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TODOs ###\n",
    "\n",
    "# TODOs: Commonsense Query and Concept Expansion: Topics, Concepts, Synonyms\n",
    "# TODOs: Domain Restrict. Polarising social and political debate (Class labelling) only for higher-quality\n",
    "# TODO: Enhance Stance Module; Determine stance over entire argument. Only implicate stance for Noun\n",
    "# TODOs: Targeted Retrieval with Semantic Graphs\n",
    "# TODOs: Multi-Field Search\n",
    "\n",
    "# DONE: Mine Args\n",
    "# DONE: Mine Counters\n",
    "# DONE: Add Concepts\n",
    "# DONE: Prior tokenization and sentence segmentation to speed processing\n",
    "# DONE: Adu, Counter + KP Extraction as 'Argument Mining' preprocessing module\n",
    "# DONE: Manage Duplicate Keywords\n",
    "# DONE: Sentential Ranking\n",
    "# DONE: Include Topic Label\n",
    "# DONE: Include Concept Label\n",
    "# DONE: Add News\n",
    "\n",
    "# TODOs: (1) coverage of topic signature words in the input statement; (2) a weighted summation of the coverage of n-grams in the argu- ment4; (3) the magnitude of stance score, where we keep the passages of the same polarity as the argument; (4) content word overlap with the argument; and (5) coverage of topic signature words in the argument."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshua.sheppard/PycharmProjects/countaBot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root = \"/Users/joshua.sheppard/PycharmProjects/countaBot\"\n",
    "os.chdir(root)\n",
    "print(os.getcwd())\n",
    "\n",
    "### INIT LOGGING ###\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"ARGUMENT-EXTRACTOR\")\n",
    "\n",
    "### NLP FUNCTIONS ###\n",
    "from src.utils.utils import tokeniser, sentences_segment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshua.sheppard/PycharmProjects/countaBot\n"
     ]
    }
   ],
   "source": [
    "### LOAD DATASETS ###\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "print(os.getcwd())\n",
    "args = [json.loads(ln) for ln in open(\"./src/data/cmv_processed.jsonl\")]\n",
    "topics = [json.loads(ln) for ln in open(\"./src/data/argument_topic_concept.jsonl\")]\n",
    "concepts = [json.loads(ln) for ln in open(\"./src/data/argument_concept.jsonl\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(5990, 5990, 10303)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics), len(concepts), len(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanks  t3_3cm6jy\n",
      "blanks  t3_1egv4k\n",
      "blanks  t3_1egv4k\n",
      "blanks  t3_5wjdve\n"
     ]
    }
   ],
   "source": [
    "### ASSERT BLANKS ###\n",
    "args_ = [json.loads(ln)[\"argument\"][\"argument\"] for ln in open(\"./src/data/cmv_processed.jsonl\")]\n",
    "ids = [json.loads(ln)[\"id\"] for ln in open(\"./src/data/cmv_processed.jsonl\")]\n",
    "\n",
    "for j, k in zip(args_, ids):\n",
    "    if j == \"\":\n",
    "        print(\"blanks\", j, k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 \n",
      "\n",
      "rewinding time is the best superpower for daily life \n",
      "\n",
      "a topic that ive had fun discussing is to imagine what could be done with a superpower. with so many choices and so many implications for each power this little game can spark long conversations on how each power would affect our daily lives. from all of these discussions ive come away with the view that one power is better than all others by the most metrics a power that i like to call rewind.disclaimer if youve never found yourself wondering what your life could be like with superpowers and have no interest in starting then this topic is definitely not for you. the topic is one massive hypothetical so that better be your thing ptldr because damn! i wrote way too much to ask you to read it all \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### INSPECT ARG ###\n",
    "import random\n",
    "sample = random.randint(0, 99)\n",
    "\n",
    "arg = args[sample][\"argument\"][\"argument\"]\n",
    "claim = args[sample][\"claim\"]\n",
    "\n",
    "print(sample, \"\\n\")\n",
    "print(claim, \"\\n\")\n",
    "print(arg, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brazil minimum income']\n",
      "['Brazil minimum income']\n",
      "['minimum']\n",
      "[]\n",
      "[]\n",
      "['brazil minimum income increasingly', 'minimum income increasingly accepted', 'income increasingly accepted', 'brazil', 'increasingly accepted']\n"
     ]
    }
   ],
   "source": [
    "### EXTRACTORS ###\n",
    "from src.utils.keyphrase_extraction import yake_extract_keyphrase, summa_extract_keyphrase\n",
    "from yake import KeywordExtractor\n",
    "import re\n",
    "\n",
    "### PHRASE CLEANER ###\n",
    "def clean(phrase):\n",
    "    return re.sub(r\"[,.;@#?!&$]+\\ *\", \" \", phrase)\n",
    "\n",
    "### YAKE PARAMS ###\n",
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_thresold = 0.9\n",
    "deduplication_algo = 'seqm'\n",
    "\n",
    "### YAKE ####\n",
    "yake_extractor = KeywordExtractor(lan=language, dedupLim=deduplication_thresold, dedupFunc=deduplication_algo, n=3)\n",
    "\n",
    "def yake_extract_keyphrase(doc, k=1):\n",
    "    kp = yake_extractor.extract_keywords(doc)\n",
    "\n",
    "    return [clean(i[0]) for i in kp][0:k]\n",
    "\n",
    "### KEYBERT ###\n",
    "from keybert import KeyBERT\n",
    "\n",
    "kb = KeyBERT()\n",
    "def extract_keyphrase(doc, n_gram=3, n_kp=3, use_mmr=\"False\", use_maxsum=\"False\"):\n",
    "    kp = kb.extract_keywords(doc, keyphrase_ngram_range=(1, 4), stop_words='english', use_mmr=True, diversity=0.5)\n",
    "\n",
    "    #return kp\n",
    "    return [clean(i[0]) for i in kp]\n",
    "\n",
    "### TEST CASES ###\n",
    "test = \"Brazil's minimum income has increasingly been accepted.\"\n",
    "ev_kp = yake_extract_keyphrase(test, k=1)\n",
    "print(ev_kp)\n",
    "\n",
    "ev_kp = yake_extract_keyphrase(test)\n",
    "ev_kp_ = summa_extract_keyphrase(test)\n",
    "\n",
    "test_2 = \" \"\n",
    "ev_kp_2 = yake_extract_keyphrase(test_2)\n",
    "ev_kp_2_ = summa_extract_keyphrase(test_2)\n",
    "\n",
    "test_3 = \"Brazil's minimum income has increasingly been accepted.\"\n",
    "ev_kp_3 = extract_keyphrase(test_3)\n",
    "\n",
    "print(ev_kp)\n",
    "print(ev_kp_)\n",
    "\n",
    "print(ev_kp_2)\n",
    "print(ev_kp_2_)\n",
    "\n",
    "print(ev_kp_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b0c40d30a2d4357bffa3a8a65dc8a6e"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.017802953720092773,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "#from src.utils_.common_sense_expansion import wordNet_expansion\n",
    "from src.detection.stance_classifier import sentence_stance, compare_stance\n",
    "import multiprocessing\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Disable Huggingface Logging\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "topic_ids = [json.loads(ln)[\"id\"] for ln in open(\"./src/data/processed/argument_topic_concept.jsonl\")]\n",
    "concept_ids = [json.loads(ln)[\"id\"] for ln in open(\"./src/data/processed/argument_concept.jsonl\")]\n",
    "\n",
    "# Where notion == topic or concept\n",
    "def get_notion(notions_ids, notions_lst, arg_id, label):\n",
    "    notion_id = notions_ids.index(arg_id)\n",
    "    notion = notions_lst[notion_id][label]\n",
    "    return str(notion) if notion else None\n",
    "\n",
    "# Extract Argument Discourse as Sentences, Keyphrases, Topics and Concepts\n",
    "def extract_adus(arg_):\n",
    "\n",
    "    id_ = arg_[\"id\"]\n",
    "    arg = arg_[\"argument\"][\"argument\"]\n",
    "\n",
    "    topic = get_notion(topic_ids, topics, id_, \"topic_label\")\n",
    "    concept = get_notion(concept_ids, concepts, id_, \"concept_label\")\n",
    "\n",
    "    adu_sents = sentences_segment(arg)\n",
    "\n",
    "    extract_adus = []\n",
    "    for _ in adu_sents:\n",
    "\n",
    "        # Limit irrelevant sentences\n",
    "        if len(tokeniser(_)) <= 5:\n",
    "            continue\n",
    "\n",
    "        kp = extract_keyphrase(_)\n",
    "\n",
    "        singleton = yake_extract_keyphrase(_, 1)\n",
    "        kp.extend(singleton)\n",
    "\n",
    "        aspect = \" \" if kp == [] else kp[0]\n",
    "\n",
    "        try:\n",
    "            stance = sentence_stance(_, aspect)\n",
    "        except:\n",
    "            stance = \" \"\n",
    "\n",
    "        adu = {\"sentence\": _, \"kp\": [i.lower() for i in kp], \"stance\": stance, \"aspect\": aspect, \"topic\": topic, \"concept\": concept}\n",
    "\n",
    "        extract_adus.append(adu)\n",
    "\n",
    "    claim = arg_[\"claim\"]\n",
    "    claim_kp = yake_extract_keyphrase(claim)\n",
    "    claim_adu = {\"sentence\": claim, \"kp\": [i for i in claim_kp]}\n",
    "\n",
    "    return ({\n",
    "        \"id\": id_,\n",
    "        \"claim\": claim_adu,\n",
    "        \"argument\": [i for i in extract_adus]\n",
    "    })\n",
    "\n",
    "mined_args = []\n",
    "\n",
    "with multiprocessing.Pool(8) as pool:\n",
    "    with tqdm(total=(len(args)), position=0, leave=True) as pbar:\n",
    "        for arg in args:\n",
    "            mined_args.append(extract_adus(arg))\n",
    "            pbar.update()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39ba0a1be66a4321ac5d2e2bf9033a3b"
      },
      "application/json": {
       "n": 0,
       "total": 10,
       "elapsed": 0.011139154434204102,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test = []\n",
    "#\n",
    "# with multiprocessing.Pool(8) as pool:\n",
    "#     with tqdm(total=(len(args[0:10])), position=0, leave=True) as pbar:\n",
    "#         for arg in args[0:10]:\n",
    "#             test.append(extract_adus(arg))\n",
    "#             pbar.update()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "# STORE DEEP-COPY\n",
    "import copy\n",
    "mined_args_ = copy.deepcopy(mined_args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10303\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'id': 't3_40uylb',\n 'claim': {'sentence': 'the oregon militia are terrorists and if they were not white but instead from a brownmiddle eastern ethnicity doing the same thing same reason theyd be called terrorists immediately',\n  'kp': ['called terrorists immediately']},\n 'argument': [{'sentence': 'can someone explain to me why these group of people in oregon are not considered terrorists and are not being called that?',\n   'kp': ['people oregon considered terrorists',\n    'oregon considered terrorists called',\n    'explain group people oregon',\n    'terrorists called',\n    'explain group',\n    'group of people'],\n   'stance': 'NEUTRAL',\n   'aspect': 'people oregon considered terrorists',\n   'topic': 'terrorist groups',\n   'concept': None},\n  {'sentence': 'not on reddit not in the media im having a tough time finding anyone saying itthey have taken a building by force with guns.. they have a political aimagenda.',\n   'kp': ['building force guns political',\n    'saying itthey taken building',\n    'reddit media im having',\n    'tough time finding',\n    'aimagenda',\n    'tough time finding'],\n   'stance': 'PRO',\n   'aspect': 'building force guns political',\n   'topic': 'terrorist groups',\n   'concept': None},\n  {'sentence': 'they also have said that they will kill anyone who enters.. how is that not terrorism?',\n   'kp': ['said kill enters terrorism',\n    'kill enters terrorism',\n    'enters terrorism',\n    'terrorism',\n    'said',\n    'enters '],\n   'stance': 'CON',\n   'aspect': 'said kill enters terrorism',\n   'topic': 'terrorist groups',\n   'concept': None},\n  {'sentence': 'if they were brown and from middle eastern origin or descent showed up and took the building and did the same exact things for the same exact reasoning they would be called terrorists immediately and people woud be up and arms over islam and blah blahinstead of telling me well they havent hurt anyone or its peaceful tell me if you went downtown in your city and took a federal building with guns would that be legal and allowed?',\n   'kp': ['building guns legal allowed',\n    'called terrorists immediately people',\n    'downtown city took federal',\n    'brown middle eastern origin',\n    'havent hurt peaceful',\n    'middle eastern origin'],\n   'stance': 'PRO',\n   'aspect': 'building guns legal allowed',\n   'topic': 'terrorist groups',\n   'concept': None},\n  {'sentence': 'thats not fuckin peacefulso why arent they being called terrorists?they cant be called protesters either.. because how about you go down to your court house with a gun and try to take it over see if they call you a protester',\n   'kp': ['peacefulso arent called terrorists',\n    'terrorists called protesters',\n    'called protesters court house',\n    'gun try protester',\n    'fuckin',\n    'called protesters either '],\n   'stance': 'NEUTRAL',\n   'aspect': 'peacefulso arent called terrorists',\n   'topic': 'terrorist groups',\n   'concept': None}]}"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mined_args\n",
    "print(len(mined_args))\n",
    "\n",
    "import random\n",
    "#_ = random.randint(0, len(sample))\n",
    "example = mined_args[10]\n",
    "example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "10303"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f1cfa59aec54e08a2acff62d4b0cf4c"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.01152801513671875,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### COUNTER-ARGS ###\n",
    "def extract_counters(arg_):\n",
    "    id_ = arg_[\"id\"]\n",
    "    counter = arg_[\"tgt_counter\"][\"tgt_counter\"]\n",
    "\n",
    "    counter_sents = sentences_segment(counter)\n",
    "\n",
    "    extract_counters = []\n",
    "    for _ in counter_sents:\n",
    "        if len(tokeniser(_)) <= 5:\n",
    "            continue\n",
    "\n",
    "        kp = extract_keyphrase(_)\n",
    "        #kp = yake_extract_keyphrase(_)\n",
    "\n",
    "        aspect = \" \" if kp == [] else kp[0]\n",
    "\n",
    "        try:\n",
    "            stance = sentence_stance(_, aspect)\n",
    "        except:\n",
    "            stance = \" \"\n",
    "\n",
    "        counter_unit = {\"sentence\": _, \"kp\": [i for i in kp], \"stance\": stance, \"aspect\": aspect}\n",
    "\n",
    "        extract_counters.append(counter_unit)\n",
    "\n",
    "    return ({\n",
    "        \"id\": id_,\n",
    "        \"tgt_counter\": [i for i in extract_counters]\n",
    "    })\n",
    "\n",
    "mined_counters = []\n",
    "\n",
    "sample = args\n",
    "with multiprocessing.Pool(8) as pool:\n",
    "    with tqdm(total=(len(args)), position=0, leave=True) as pbar:\n",
    "        for arg in args:\n",
    "            mined_counters.append(extract_counters(arg))\n",
    "            pbar.update()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "import copy\n",
    "mined_counters_ = copy.deepcopy(mined_counters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10303\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'id': 't3_1kye6l',\n 'tgt_counter': [{'sentence': 'why do you feel like you need to start drinking?',\n   'kp': ['need start drinking',\n    'drinking',\n    'feel like need start',\n    'feel like',\n    'need'],\n   'stance': 'PRO',\n   'aspect': 'need start drinking'},\n  {'sentence': 'it doesnt make you boring unless the only way you define interesting is through drinking which is pretty flawed.',\n   'kp': ['define interesting drinking',\n    'doesnt make boring unless',\n    'way define interesting',\n    'interesting',\n    'pretty flawed'],\n   'stance': 'PRO',\n   'aspect': 'define interesting drinking'},\n  {'sentence': 'there is nothing wrong with not drinking.',\n   'kp': ['wrong drinking', 'drinking', 'wrong'],\n   'stance': 'CON',\n   'aspect': 'wrong drinking'},\n  {'sentence': 'you totally can grow up sipping cola always and everywhere without being a freak or a sideshow attraction.',\n   'kp': ['grow sipping cola freak',\n    'sipping cola freak sideshow',\n    'cola freak sideshow attraction',\n    'sideshow attraction',\n    'totally'],\n   'stance': 'PRO',\n   'aspect': 'grow sipping cola freak'},\n  {'sentence': 'most everyone thats not a vapid idiot will respect your life decisions.personally i weathered most of college without drinking and didnt start until i was .',\n   'kp': ['personally weathered college drinking',\n    'college drinking didnt',\n    'idiot respect life decisions',\n    'drinking didnt start',\n    'vapid'],\n   'stance': 'PRO',\n   'aspect': 'personally weathered college drinking'},\n  {'sentence': 'i dont feel like it negatively impacted me in any significant way.',\n   'kp': ['feel like negatively impacted',\n    'negatively impacted significant way',\n    'dont feel like negatively',\n    'significant way',\n    'dont'],\n   'stance': 'PRO',\n   'aspect': 'feel like negatively impacted'},\n  {'sentence': 'in fact i think waiting to drink helped me to view alcohol in a more healthy way since my experience has been almost entirely of the having a beer with dinner variety.as someone that was fearful of alcohol and drugs myself at your age the biggest thing you can remember is that all substances are just things.',\n   'kp': ['drink helped view alcohol',\n    'fearful alcohol drugs age',\n    'beer dinner variety fearful',\n    'healthy way experience entirely',\n    'waiting'],\n   'stance': 'PRO',\n   'aspect': 'drink helped view alcohol'},\n  {'sentence': 'its very easy to set any controlled substances aside as some exceptional magical substances that will ruin your lifeturn you into a stonergive you cancermake you cool.',\n   'kp': ['set controlled substances aside',\n    'ruin lifeturn stonergive cancermake',\n    'magical substances ruin lifeturn',\n    'magical',\n    'easy set'],\n   'stance': 'PRO',\n   'aspect': 'set controlled substances aside'},\n  {'sentence': 'if you start drinking youre not going to be a substantively different person.',\n   'kp': ['drinking youre going substantively',\n    'start drinking',\n    'substantively different',\n    'different person',\n    'youre'],\n   'stance': 'NEUTRAL',\n   'aspect': 'drinking youre going substantively'},\n  {'sentence': 'this is both a positive and a negative.',\n   'kp': ['positive negative', 'positive', 'negative'],\n   'stance': 'PRO',\n   'aspect': 'positive negative'},\n  {'sentence': 'if your intention is to start drinking to fit in better its not going to be as effective as youd like.',\n   'kp': ['start drinking fit better',\n    'start drinking',\n    'intention start drinking',\n    'fit better going effective',\n    'going effective youd like'],\n   'stance': 'PRO',\n   'aspect': 'start drinking fit better'}]}"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mined_args\n",
    "print(len(mined_counters))\n",
    "\n",
    "import random\n",
    "_ = random.randint(0, len(sample))\n",
    "example = mined_counters[_]\n",
    "example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "(10303, 10303)"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args), len(mined_counters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "(10303, 10303)"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args_), len(mined_counters_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshua.sheppard/PycharmProjects/countaBot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87e34f84debf49e682de013baf40b164"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.01081228256225586,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ARGUMENT-EXTRACTOR:[10303 Data Stored as cmv_argument_extraction.jsonl]\n"
     ]
    }
   ],
   "source": [
    "file_name = \"cmv_argument_extraction\"\n",
    "fout = open(f\"./src/data/processed/{file_name}.jsonl\", \"w\")\n",
    "\n",
    "# Deep_copies\n",
    "mined_args_ = copy.deepcopy(mined_args)\n",
    "mined_counters_ = copy.deepcopy(mined_counters)\n",
    "\n",
    "with tqdm(total=(len(mined_args_))) as pbar:\n",
    "    with fout:\n",
    "        for mined_arg, mined_counter in zip(mined_args_, mined_counters_):\n",
    "            # Extended pre-formatted mined object\n",
    "            mined_arg[\"tgt_counter\"] = [_ for _ in mined_counter[\"tgt_counter\"]]\n",
    "\n",
    "            fout.write(json.dumps(mined_arg))\n",
    "\n",
    "            fout.write(\"\\n\")\n",
    "            pbar.update()\n",
    "\n",
    "logger.info(f\"[{len(mined_args_)} Data Stored as {file_name}.jsonl]\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "### EVALUATE OUTPUT ###\n",
    "train = [json.loads(ln) for ln in open(f\"./src/data/processed/{file_name}.jsonl\", \"r\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "10303"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3_3s7hmb \n",
      "\n",
      "[{'sentence': 'lets see what is the us at?life expectancy?corruption?gdp per capita?equality?upward mobility?education?freedom from corruption?internet speeds?environmentalism?peacelowest murder rates?average wealth?median wealth?median income?economic freedom according to the conservative heritage foundation?the correct answer is none of these.', 'kp': ['economic freedom according conservative', 'rates average wealth', 'life expectancy corruption gdp', 'median', 'foundation correct', 'peacelowest murder rates'], 'stance': 'PRO', 'aspect': 'economic freedom according conservative', 'topic': None, 'concept': None}, {'sentence': 'a mix of hong kong singapore scandinavian countries switzerland canada and australia take up most of these rankings.', 'kp': ['singapore scandinavian countries switzerland', 'hong kong singapore scandinavian', 'canada australia rankings', 'mix hong kong', 'australia', 'hong kong singapore'], 'stance': 'NEUTRAL', 'aspect': 'singapore scandinavian countries switzerland', 'topic': None, 'concept': None}, {'sentence': 'so what is the us at?incarceration rate some years it dips to depending on how many somali pirates are in jail in the seychelles probably not a good thing in the eyes of most religions secular value systems or votersguns per capita debatable.', 'kp': ['somali pirates jail seychelles', 'seychelles probably good thing', 'incarceration rate years dips', 'votersguns capita debatable', 'religions secular value', 'incarceration rate'], 'stance': 'PRO', 'aspect': 'somali pirates jail seychelles', 'topic': None, 'concept': None}, {'sentence': 'except for hardrightwingers most nonamericans and many americans would argue that the us has far too many guns.healthcare spending only a good thing if youre a pharma manufacturer or a eurocrat who wants to keep manufacturing as a of gdp above some arbitrary number.also one can raise all sorts of cain about how the nice countries have massive levels of household debt andor are affected by the economic downturn now but even in when sweden denmark canada and hell even spain were cleaning our clock having us out to lunch and laughing at us people were saying murricah is the greatis cuntry in the werreld!', 'kp': ['guns healthcare spending good', 'hardrightwingers nonamericans americans argue', 'countries massive levels household', 'saying murricah', 'thing youre pharma manufacturer', 'household debt andor'], 'stance': 'PRO', 'aspect': 'guns healthcare spending good', 'topic': None, 'concept': None}, {'sentence': 'this delusional thinking is a danger to progress it was so uplifting to go on vacation to colombia and see colombians hoping for a new country with peace and equality while americans are stuck in the abyss of denial.', 'kp': ['colombians hoping new country', 'delusional thinking danger progress', 'americans stuck abyss denial', 'progress uplifting vacation', 'peace equality americans stuck', 'abyss of denial'], 'stance': 'PRO', 'aspect': 'colombians hoping new country', 'topic': None, 'concept': None}] \n",
      "\n",
      "[{'sentence': 'it might be better to think of it as a confederation of countries california has a greater gpd than australia for example.', 'kp': ['countries california greater gpd', 'greater gpd australia example', 'confederation countries california greater', 'better think confederation', 'australia example'], 'stance': 'PRO', 'aspect': 'countries california greater gpd'}, {'sentence': 'so predictably since there are a lot of countries with a lot of economic situations some countries will come off better than the usa by certain measures.', 'kp': ['countries come better usa', 'predictably lot countries', 'usa certain measures', 'lot economic situations', 'predictably'], 'stance': 'PRO', 'aspect': 'countries come better usa'}, {'sentence': 'an oil rich country like norway will find it a lot easier to have a social welfare net than a poor state with a low gpd like mississippi with few businesses.that saidthe us has the best five year survival rate for cancer ignoring car accidents and homicide the highest life expectancy.the us is a technological giant.', 'kp': ['best year survival rate', 'rich country like norway', 'easier social welfare', 'cancer ignoring car accidents', 'low gpd like mississippi'], 'stance': 'PRO', 'aspect': 'best year survival rate'}, {'sentence': 'they have the most nobel laureates.', 'kp': ['nobel laureates', 'laureates', 'nobel'], 'stance': 'NEUTRAL', 'aspect': 'nobel laureates'}, {'sentence': 'the best medical science as mentioned above.', 'kp': ['best medical science mentioned', 'best medical science', 'best medical', 'science', 'best'], 'stance': 'PRO', 'aspect': 'best medical science mentioned'}, {'sentence': 'the technologically most powerful military as mentioned elsewhere.the top country for movie production.the top researcher of the world.the usas military dominance has helped herald in a new era of peace.', 'kp': ['technologically powerful military', 'world usas military dominance', 'country movie production researcher', 'world usas', 'new era peace'], 'stance': 'PRO', 'aspect': 'technologically powerful military'}, {'sentence': 'their movies go to every country in the world spreading culture.', 'kp': ['movies country world spreading', 'country world spreading culture', 'movies', 'culture', 'spreading'], 'stance': 'NEUTRAL', 'aspect': 'movies country world spreading'}, {'sentence': 'their medical technology keeps their civilians alive.', 'kp': ['medical technology keeps civilians', 'keeps civilians alive', 'civilians alive', 'technology keeps', 'alive'], 'stance': 'NEUTRAL', 'aspect': 'medical technology keeps civilians'}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = random.randint(0, len(train))\n",
    "print(train[_][\"id\"], \"\\n\")\n",
    "print(train[_][\"argument\"], \"\\n\")\n",
    "print(train[_][\"tgt_counter\"], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i, j in zip(retrieved_ranked, sample):\n",
    "#     # Add counter to the dictionary (implicitly, i)\n",
    "#     i[\"counter\"] = j[\"counter\"]\n",
    "#     fout.write(json.dumps(i))\n",
    "#     fout.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Working Loop\n",
    "# for i in mined_counters_:\n",
    "#     test = {\n",
    "#         \"test\": [j for j in i[\"counter\"]]\n",
    "#     }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BATCH LOADING\n",
    "\n",
    "# STEPS = 10\n",
    "# STEP = max(int(len(SAMPLE) / STEPS), 1)\n",
    "# BATCHES = [sample[i:i + STEP] for i in range(0, len(SAMPLE), STEP)]\n",
    "#\n",
    "# mined_counters = []\n",
    "# for idx, batch in enumerate(BATCHES):\n",
    "#     print('-' * 25 + 'Batch %d/%d' % (idx + 1, len(BATCHES)) + '-' * 25)\n",
    "#\n",
    "#     with multiprocessing.Pool(8) as pool:\n",
    "#         with tqdm(total=(len(batch))) as pbar:\n",
    "#             for counter in batch:\n",
    "#                 mined_counters.append(extract_counters(counter))\n",
    "#                 pbar.update()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
