{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TODOs ###\n",
    "\n",
    "# TODOs: Commonsense Query and Concept Expansion: Topics, Concepts, Synonyms\n",
    "# TODOs: Domain Restrict. Polarising social and political debate (Class labelling) only for higher-quality\n",
    "# TODO: Enhance Stance Module; Determine stance over entire argument. Only implicate stance for Noun\n",
    "# TODOs: Targeted Retrieval with Semantic Graphs\n",
    "# TODOs: Multi-Field Search\n",
    "\n",
    "# DONE: Mine Args\n",
    "# DONE: Mine Counters\n",
    "# DONE: Add Concepts\n",
    "# DONE: Prior tokenization and sentence segmentation to speed processing\n",
    "# DONE: Adu, Counter + KP Extraction as 'Argument Mining' preprocessing module\n",
    "# DONE: Manage Duplicate Keywords\n",
    "# DONE: Sentential Ranking\n",
    "# DONE: Include Topic Label\n",
    "# DONE: Include Concept Label\n",
    "# DONE: Add News\n",
    "\n",
    "# TODOs: (1) coverage of topic signature words in the input statement; (2) a weighted summation of the coverage of n-grams in the argu- ment4; (3) the magnitude of stance score, where we keep the passages of the same polarity as the argument; (4) content word overlap with the argument; and (5) coverage of topic signature words in the argument."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshua.sheppard/PycharmProjects/countaBot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root = \"/Users/joshua.sheppard/PycharmProjects/countaBot\"\n",
    "os.chdir(root)\n",
    "print(os.getcwd())\n",
    "\n",
    "### INIT LOGGING ###\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"ARGUMENT-EXTRACTOR\")\n",
    "\n",
    "### NLP FUNCTIONS ###\n",
    "from src.utils_.utils import tokeniser, sentences_segment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshua.sheppard/PycharmProjects/countaBot\n"
     ]
    }
   ],
   "source": [
    "### LOAD DATASETS ###\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "print(os.getcwd())\n",
    "args = [json.loads(ln) for ln in open(\"./src/data/cmv_processed.jsonl\")]\n",
    "topics = [json.loads(ln) for ln in open(\"./src/data/argument_topic_concept.jsonl\")]\n",
    "concepts = [json.loads(ln) for ln in open(\"./src/data/argument_concept.jsonl\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(5990, 5990, 10303)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics), len(concepts), len(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanks  t3_3cm6jy\n",
      "blanks  t3_1egv4k\n",
      "blanks  t3_1egv4k\n",
      "blanks  t3_5wjdve\n"
     ]
    }
   ],
   "source": [
    "### ASSERT BLANKS ###\n",
    "args_ = [json.loads(ln)[\"argument\"][\"argument\"] for ln in open(\"./src/data/cmv_processed.jsonl\")]\n",
    "ids = [json.loads(ln)[\"id\"] for ln in open(\"./src/data/cmv_processed.jsonl\")]\n",
    "\n",
    "for j, k in zip(args_, ids):\n",
    "    if j == \"\":\n",
    "        print(\"blanks\", j, k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 \n",
      "\n",
      "rewinding time is the best superpower for daily life \n",
      "\n",
      "a topic that ive had fun discussing is to imagine what could be done with a superpower. with so many choices and so many implications for each power this little game can spark long conversations on how each power would affect our daily lives. from all of these discussions ive come away with the view that one power is better than all others by the most metrics a power that i like to call rewind.disclaimer if youve never found yourself wondering what your life could be like with superpowers and have no interest in starting then this topic is definitely not for you. the topic is one massive hypothetical so that better be your thing ptldr because damn! i wrote way too much to ask you to read it all \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### INSPECT ARG ###\n",
    "import random\n",
    "sample = random.randint(0, 99)\n",
    "\n",
    "arg = args[sample][\"argument\"][\"argument\"]\n",
    "claim = args[sample][\"claim\"]\n",
    "\n",
    "print(sample, \"\\n\")\n",
    "print(claim, \"\\n\")\n",
    "print(arg, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brazil minimum income', 'minimum income has increasingly', 'Brazil minimum', 'increasingly been accepted', 'minimum income']\n",
      "['minimum']\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "### EXTRACTORS ###\n",
    "from src.utils_.keyphrase_extraction import yake_extract_keyphrase, summa_extract_keyphrase\n",
    "\n",
    "test = \"Brazil's minimum income has increasingly been accepted.\"\n",
    "ev_kp = yake_extract_keyphrase(test)\n",
    "ev_kp_ = summa_extract_keyphrase(test)\n",
    "\n",
    "test_2 = \" \"\n",
    "ev_kp_2 = yake_extract_keyphrase(test_2)\n",
    "ev_kp_2_ = summa_extract_keyphrase(test_2)\n",
    "\n",
    "print(ev_kp)\n",
    "print(ev_kp_)\n",
    "\n",
    "# Can Handel Blanks\n",
    "print(ev_kp_2)\n",
    "print(ev_kp_2_)\n",
    "\n",
    "### KEYBERT ###\n",
    "from keybert import KeyBERT\n",
    "\n",
    "kb = KeyBERT()\n",
    "def extract_keyphrase(doc, n_gram=3, n_kp=3, use_mmr=\"False\", use_maxsum=\"False\"):\n",
    "    kp = kb.extract_keywords(doc, keyphrase_ngram_range=(1, 4), stop_words='english', use_mmr=True, diversity=0.5)\n",
    "\n",
    "    return [i[0] for i in kp]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "df8509d7080244b8abe2aac81b747e29"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.01265406608581543,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from src.utils_.word_net_expansion import expand_query\n",
    "import multiprocessing\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Disable Huggingface Logging\n",
    "import os\n",
    "os.chdir(home)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "topic_ids = [json.loads(ln)[\"id\"] for ln in open(\"./src/data/argument_topic_concept.jsonl\")]\n",
    "concept_ids = [json.loads(ln)[\"id\"] for ln in open(\"./src/data/argument_concept.jsonl\")]\n",
    "\n",
    "# path = \"/Users/joshua.sheppard/PycharmProjects/countaBot/src/retriever/\"\n",
    "# os.chdir(path)\n",
    "from src.detection.stance_classifier import sentence_stance\n",
    "from src.detection.stance_classifier import sentence_stance, compare_stance\n",
    "\n",
    "# Where notion == topic or concept\n",
    "def get_notion(notions_ids, notions_lst, arg_id, label):\n",
    "    notion_id = notions_ids.index(arg_id)\n",
    "    notion = notions_lst[notion_id][label]\n",
    "    return str(notion) if notion else None\n",
    "\n",
    "# Extract Argument Discourse as Sentences, Keyphrases, Topics and Concepts\n",
    "def extract_adus(arg_):\n",
    "\n",
    "    id_ = arg_[\"id\"]\n",
    "    arg = arg_[\"argument\"][\"argument\"]\n",
    "\n",
    "    topic = get_notion(topic_ids, topics, id_, \"topic_label\")\n",
    "    concept = get_notion(concept_ids, concepts, id_, \"concept_label\")\n",
    "\n",
    "    adu_sents = sentences_segment(arg)\n",
    "\n",
    "    extract_adus = []\n",
    "    for _ in adu_sents:\n",
    "\n",
    "        # Limit irrelevant sentences\n",
    "        if len(tokeniser(_)) <= 5:\n",
    "            continue\n",
    "\n",
    "        kp = extract_keyphrase(_)\n",
    "        #kp = yake_extract_keyphrase(_)\n",
    "\n",
    "        aspect = \" \" if kp == [] else kp[0]\n",
    "\n",
    "        try:\n",
    "            stance = sentence_stance(_, aspect)\n",
    "        except:\n",
    "            stance = \" \"\n",
    "\n",
    "        adu = {\"sentence\": _, \"kp\": [i.lower() for i in kp], \"stance\": stance, \"aspect\": aspect, \"topic\": topic, \"concept\": concept}\n",
    "\n",
    "        extract_adus.append(adu)\n",
    "\n",
    "    claim = arg_[\"claim\"]\n",
    "    claim_kp = yake_extract_keyphrase(claim)\n",
    "    claim_adu = {\"sentence\": claim, \"kp\": [i for i in claim_kp]}\n",
    "\n",
    "    return ({\n",
    "        \"id\": id_,\n",
    "        \"claim\": claim_adu,\n",
    "        \"argument\": [i for i in extract_adus]\n",
    "    })\n",
    "\n",
    "mined_args = []\n",
    "\n",
    "with multiprocessing.Pool(8) as pool:\n",
    "    with tqdm(total=(len(args)), position=0, leave=True) as pbar:\n",
    "        for arg in args:\n",
    "            mined_args.append(extract_adus(arg))\n",
    "            pbar.update()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# STORE DEEP-COPY\n",
    "import copy\n",
    "mined_args_ = copy.deepcopy(mined_args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10303\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'id': 't3_30oi71',\n 'claim': {'sentence': 'we should strengthen the traditional safety net rather than replace it with basic income',\n  'kp': ['strengthen the traditional safety',\n   'traditional safety net',\n   'basic income',\n   'strengthen the traditional',\n   'traditional safety']},\n 'argument': [{'sentence': 'section i why is basic income increasingly popular?',\n   'kp': ['basic income increasingly popular',\n    'section basic income',\n    'basic',\n    'increasingly',\n    'section'],\n   'stance': 'PRO',\n   'aspect': 'basic income increasingly popular',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'basic income is a policy that has broad support from both the progressive left and libertarian right.',\n   'kp': ['basic income',\n    'basic income policy',\n    'basic income policy broad',\n    'income policy broad support',\n    'support progressive left libertarian'],\n   'stance': 'PRO',\n   'aspect': 'basic income',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'centerleft economists including paul krugman have endorsed the scheme for various reasons.',\n   'kp': ['paul krugman endorsed scheme',\n    'economists including paul krugman',\n    'centerleft economists including',\n    'endorsed scheme various reasons',\n    'various reasons'],\n   'stance': 'PRO',\n   'aspect': 'paul krugman endorsed scheme',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'first bi is an effective antipoverty measure.',\n   'kp': ['bi effective antipoverty measure',\n    'bi effective antipoverty',\n    'bi effective',\n    'bi',\n    'measure'],\n   'stance': 'PRO',\n   'aspect': 'bi effective antipoverty measure',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'bi also reduces inequality by redistributing income from capital to labor.',\n   'kp': ['bi reduces inequality redistributing',\n    'reduces inequality redistributing income',\n    'income capital labor',\n    'reduces',\n    'redistributing'],\n   'stance': 'CON',\n   'aspect': 'bi reduces inequality redistributing',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'perhaps most importantly to some on the left is the notion that bi provides people with freedom.',\n   'kp': ['bi provides people freedom',\n    'left notion',\n    'freedom',\n    'notion bi provides',\n    'importantly'],\n   'stance': 'PRO',\n   'aspect': 'bi provides people freedom',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'leftlibertarian political economist philippe van parijs argues that to be truly free people have to have access to the means that people need for doing what they might want to do.',\n   'kp': ['parijs argues truly free',\n    'free people access means',\n    'political economist philippe van',\n    'people need doing want',\n    'leftlibertarian'],\n   'stance': 'PRO',\n   'aspect': 'parijs argues truly free',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'bi provides people those means.',\n   'kp': ['bi provides people means',\n    'bi provides people',\n    'bi provides',\n    'bi',\n    'means'],\n   'stance': 'NEUTRAL',\n   'aspect': 'bi provides people means',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'some have made a feminist case for bi.',\n   'kp': ['feminist case bi', 'feminist case', 'case bi', 'bi', 'feminist'],\n   'stance': 'NEUTRAL',\n   'aspect': 'feminist case bi',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'philosopher carole pateman writes bi would for the first time provide women with lifelong modest economic independence and security a major reason why it is central to democratization.basic income particularly in the form of a negative income tax is also popular among the libertarian right.',\n   'kp': ['democratization basic income particularly',\n    'popular libertarian',\n    'independence security major reason',\n    'bi time provide women',\n    'philosopher carole pateman writes'],\n   'stance': 'PRO',\n   'aspect': 'democratization basic income particularly',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'with a nit in place much of the welfare state would be obsolete you could get rid of food stamps child nutrition programs public housing cash welfare community development programs medicaid and a host of meanstested welfare programs.',\n   'kp': ['nit place welfare state',\n    'welfare state obsolete rid',\n    'rid food stamps child',\n    'community development programs medicaid',\n    'obsolete rid food'],\n   'stance': 'CON',\n   'aspect': 'nit place welfare state',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'it would simplify the bureaucracy and get rid of the unemployment trap that occurs under the existing system.',\n   'kp': ['simplify bureaucracy rid unemployment',\n    'unemployment trap occurs existing',\n    'rid unemployment',\n    'occurs existing',\n    'rid'],\n   'stance': 'PRO',\n   'aspect': 'simplify bureaucracy rid unemployment',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'}]}"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mined_args\n",
    "print(len(mined_args))\n",
    "\n",
    "import random\n",
    "#_ = random.randint(0, len(sample))\n",
    "example = mined_args[1]\n",
    "example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "10303"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "414317915aa04b4b9833feb25b85fd2a"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.01591205596923828,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### COUNTER-ARGS ###\n",
    "def extract_counters(arg_):\n",
    "    id_ = arg_[\"id\"]\n",
    "    counter = arg_[\"tgt_counter\"][\"tgt_counter\"]\n",
    "\n",
    "    counter_sents = sentences_segment(counter)\n",
    "\n",
    "    extract_counters = []\n",
    "    for _ in counter_sents:\n",
    "        if len(tokeniser(_)) <= 5:\n",
    "            continue\n",
    "\n",
    "        kp = extract_keyphrase(_)\n",
    "        #kp = yake_extract_keyphrase(_)\n",
    "\n",
    "        aspect = \" \" if kp == [] else kp[0]\n",
    "\n",
    "        try:\n",
    "            stance = sentence_stance(_, aspect)\n",
    "        except:\n",
    "            stance = \" \"\n",
    "\n",
    "        counter_unit = {\"sentence\": _, \"kp\": [i for i in kp], \"stance\": stance, \"aspect\": aspect}\n",
    "\n",
    "        extract_counters.append(counter_unit)\n",
    "\n",
    "    return ({\n",
    "        \"id\": id_,\n",
    "        \"tgt_counter\": [i for i in extract_counters]\n",
    "    })\n",
    "\n",
    "mined_counters = []\n",
    "\n",
    "sample = args\n",
    "with multiprocessing.Pool(8) as pool:\n",
    "    with tqdm(total=(len(args)), position=0, leave=True) as pbar:\n",
    "        for arg in args:\n",
    "            mined_counters.append(extract_counters(arg))\n",
    "            pbar.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import copy\n",
    "mined_counters_ = copy.deepcopy(mined_counters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10303\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'id': 't3_2htk52',\n 'tgt_counter': [{'sentence': 'commercial dry dog food is full of additives preservatives rendered animal products meat not inspected as safe for humans etc.',\n   'kp': ['commercial dry dog food',\n    'additives preservatives rendered animal',\n    'preservatives rendered animal products',\n    'rendered animal products meat',\n    'commercial dry dog'],\n   'stance': 'PRO',\n   'aspect': 'commercial dry dog food'},\n  {'sentence': 'some people think dog kibble isnt even healthy for the dog some of the chemicals theyre worried about include bht and ethoxyquin.',\n   'kp': ['include bht and ethoxyquin',\n    'kibble isnt even healthy',\n    'chemicals theyre worried',\n    'theyre worried about include',\n    'worried about include bht'],\n   'stance': 'PRO',\n   'aspect': 'include bht and ethoxyquin'},\n  {'sentence': 'if the child ate one or two pieces once thats not the end of the world.',\n   'kp': ['child ate', 'end of the world', 'world', 'child', 'ate'],\n   'stance': 'NEUTRAL',\n   'aspect': 'child ate'},\n  {'sentence': 'but you cant let him help himself every time hes crawling the kitchen floor.',\n   'kp': ['crawling the kitchen floor',\n    'time hes crawling',\n    'hes crawling the kitchen',\n    'kitchen floor',\n    'time hes'],\n   'stance': 'NEUTRAL',\n   'aspect': 'crawling the kitchen floor'},\n  {'sentence': 'it only takes a second to pick the bowl up.',\n   'kp': ['pick the bowl', 'pick', 'bowl'],\n   'stance': 'NEUTRAL',\n   'aspect': 'pick the bowl'}]}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mined_args\n",
    "print(len(mined_counters))\n",
    "\n",
    "import random\n",
    "_ = random.randint(0, len(sample))\n",
    "example = mined_counters[_]\n",
    "example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(10303, 10303)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args), len(mined_counters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(10303, 10303)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args_), len(mined_counters_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshua.sheppard/PycharmProjects/countaBot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9323eaf487234c60ab038293a8827fa5"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.008214950561523438,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ARGUMENT-EXTRACTOR:[10303 Data Stored as cmv_argument_extraction.jsonl]\n"
     ]
    }
   ],
   "source": [
    "file_name = \"cmv_argument_extraction\"\n",
    "fout = open(f\"./src/data/{file_name}.jsonl\", \"w\")\n",
    "\n",
    "# Deep_copies\n",
    "mined_args_ = copy.deepcopy(mined_args)\n",
    "mined_counters_ = copy.deepcopy(mined_counters)\n",
    "\n",
    "with tqdm(total=(len(mined_args_))) as pbar:\n",
    "    with fout:\n",
    "        for mined_arg, mined_counter in zip(mined_args_, mined_counters_):\n",
    "            # Extended pre-formatted mined object\n",
    "            # mined_arg[\"original_post\"] = original_post[\"argument\"]\n",
    "            mined_arg[\"tgt_counter\"] = [_ for _ in mined_counter[\"tgt_counter\"]]\n",
    "\n",
    "            fout.write(json.dumps(mined_arg))\n",
    "\n",
    "            fout.write(\"\\n\")\n",
    "            pbar.update()\n",
    "\n",
    "logger.info(f\"[{len(mined_args_)} Data Stored as {file_name}.jsonl]\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "### EVALUATE OUTPUT ###\n",
    "train = [json.loads(ln) for ln in open(f\"../data/{file_name}.jsonl\", \"r\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "10303"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3_2dqwmd \n",
      "\n",
      "[{'sentence': 'Let me start off by saying that Im a gay guy.', 'kp': ['gay guy', 'guy', 'start', 'gay'], 'stance': 'NEUTRAL', 'aspect': 'gay guy', 'topic': None, 'concept': 'gay guy'}, {'sentence': 'Im not really viewing this from the outside in though perhaps that perspective is what I need.Im nineteen years old now coming to realization with my sexuality when I had just turned thirteen years old.', 'kp': ['need.Im nineteen years', 'turned thirteen years', 'need.Im nineteen', 'coming to realization', 'turned thirteen'], 'stance': 'NEUTRAL', 'aspect': 'need.Im nineteen years', 'topic': None, 'concept': 'need.Im nineteen years'}, {'sentence': 'I was a loner who read wrote and gamed in my spare time rather than hang out with friends.', 'kp': ['loner who read', 'read wrote', 'wrote and gamed', 'spare time', 'friends'], 'stance': 'CON', 'aspect': 'loner who read', 'topic': None, 'concept': 'loner who read'}, {'sentence': 'People instantly expected me to talk with a lisp walk with a strut and love shopping.', 'kp': ['People instantly expected', 'People instantly', 'love shopping', 'instantly expected', 'lisp walk'], 'stance': 'PRO', 'aspect': 'People instantly expected', 'topic': None, 'concept': 'People instantly expected'}, {'sentence': 'People equated me to being a gay best friend on merit of that.', 'kp': ['People equated', 'gay best friend', 'friend on merit', 'People', 'equated'], 'stance': 'PRO', 'aspect': 'People equated', 'topic': None, 'concept': 'People equated'}] \n",
      "\n",
      "[{'sentence': 'Generally when you are in a discriminated against minority youve got two choices try to blend in or take ownership of the stereotype.Theres nothing wrong at all with you just being you and wanting your sexual preference to be treated no different than being left handed youre different than the majority and you do things a little differently than they do but no big deal.But the other approach is to say you think thats effeminate?', 'kp': ['left handed youre', 'discriminated against minority', 'minority youve', 'stereotype.Theres nothing wrong', 'wanting your sexual'], 'stance': 'CON', 'aspect': 'left handed youre'}, {'sentence': 'Not that I think gays are effeminate but that that was the stereotype.', 'kp': ['gays are effeminate', 'stereotype', 'gays', 'effeminate'], 'stance': 'CON', 'aspect': 'gays are effeminate'}, {'sentence': 'Im also enough that when I was young when people would say You know Bill?', 'kp': ['young when people', 'Bill', 'young', 'people'], 'stance': 'PRO', 'aspect': 'young when people'}, {'sentence': 'I just found out that hes gay they made sure to whisper the last word.', 'kp': ['hes gay', 'gay they made', 'word', 'found', 'hes'], 'stance': 'NEUTRAL', 'aspect': 'hes gay'}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = random.randint(0, len(train))\n",
    "print(train[_][\"id\"], \"\\n\")\n",
    "print(train[_][\"argument\"], \"\\n\")\n",
    "print(train[_][\"tgt_counter\"], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i, j in zip(retrieved_ranked, sample):\n",
    "#     # Add counter to the dictionary (implicitly, i)\n",
    "#     i[\"counter\"] = j[\"counter\"]\n",
    "#     fout.write(json.dumps(i))\n",
    "#     fout.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Working Loop\n",
    "# for i in mined_counters_:\n",
    "#     test = {\n",
    "#         \"test\": [j for j in i[\"counter\"]]\n",
    "#     }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# BATCH LOADING\n",
    "\n",
    "# STEPS = 10\n",
    "# STEP = max(int(len(SAMPLE) / STEPS), 1)\n",
    "# BATCHES = [sample[i:i + STEP] for i in range(0, len(SAMPLE), STEP)]\n",
    "#\n",
    "# mined_counters = []\n",
    "# for idx, batch in enumerate(BATCHES):\n",
    "#     print('-' * 25 + 'Batch %d/%d' % (idx + 1, len(BATCHES)) + '-' * 25)\n",
    "#\n",
    "#     with multiprocessing.Pool(8) as pool:\n",
    "#         with tqdm(total=(len(batch))) as pbar:\n",
    "#             for counter in batch:\n",
    "#                 mined_counters.append(extract_counters(counter))\n",
    "#                 pbar.update()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
