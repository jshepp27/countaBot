{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# try:\n",
    "#     from cStringIO import StringIO\n",
    "# except:\n",
    "#     from StringIO import StringIO\n",
    "\n",
    "# Let's fetch the Common Crawl FAQ using the CC index\n",
    "resp = requests.get('http://index.commoncrawl.org/CC-MAIN-2015-27-index?url=http%3A%2F%2Fcommoncrawl.org%2Ffaqs%2F&output=json')\n",
    "resp_ = resp.content.strip().split(bytes(\"\\n\", encoding=\"utf-8\"))\n",
    "\n",
    "pages = [json.loads(x) for x in resp_]\n",
    "# # Multiple pages may have been found - we're only interested in one\n",
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "{'urlkey': 'org,commoncrawl)/faqs',\n 'timestamp': '20150701063137',\n 'url': 'http://commoncrawl.org/faqs/',\n 'mime': 'text/html',\n 'status': '200',\n 'digest': 'ANEUZJSAIX4UDD2PRWXB2SEIKXBVXKO2',\n 'length': '4406',\n 'offset': '53124164',\n 'filename': 'crawl-data/CC-MAIN-2015-27/segments/1435375094690.4/warc/CC-MAIN-20150627031814-00274-ip-10-179-60-89.ec2.internal.warc.gz'}"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON response from index.commoncrawl.org\n",
      "---\n",
      "{'urlkey': 'org,commoncrawl)/faqs', 'timestamp': '20150701063137', 'url': 'http://commoncrawl.org/faqs/', 'mime': 'text/html', 'status': '200', 'digest': 'ANEUZJSAIX4UDD2PRWXB2SEIKXBVXKO2', 'length': '4406', 'offset': '53124164', 'filename': 'crawl-data/CC-MAIN-2015-27/segments/1435375094690.4/warc/CC-MAIN-20150627031814-00274-ip-10-179-60-89.ec2.internal.warc.gz'}\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Input \u001B[0;32mIn [28]\u001B[0m, in \u001B[0;36m<cell line: 19>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m resp \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mget(prefix \u001B[38;5;241m+\u001B[39m page[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfilename\u001B[39m\u001B[38;5;124m'\u001B[39m], headers\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRange\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbytes=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(offset, offset_end)})\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# The page is stored compressed (gzip) to save space\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# We can extract it using the GZIP library\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m raw_data \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m f \u001B[38;5;241m=\u001B[39m gzip\u001B[38;5;241m.\u001B[39mGzipFile(fileobj\u001B[38;5;241m=\u001B[39mraw_data)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# What we have now is just the WARC response, formatted:\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    341\u001B[0m     s \u001B[38;5;241m=\u001B[39m s\u001B[38;5;241m.\u001B[39mdecode(detect_encoding(s), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msurrogatepass\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m JSONDecoder\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecode\u001B[39m(\u001B[38;5;28mself\u001B[39m, s, _w\u001B[38;5;241m=\u001B[39mWHITESPACE\u001B[38;5;241m.\u001B[39mmatch):\n\u001B[1;32m    333\u001B[0m     \u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03m    containing a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m     end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n\u001B[1;32m    339\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(s):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    353\u001B[0m     obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscan_once(s, idx)\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "# If we print this, we'll see the JSON representation of the response\n",
    "# Most important is the file path to read and the location within the large file that the GZIP response exists\n",
    "print('JSON response from index.commoncrawl.org')\n",
    "print('---')\n",
    "print(page)\n",
    "\n",
    "# We need to calculate the start and the end of the relevant byte range\n",
    "# (each WARC file is composed of many small GZIP files stuck together)\n",
    "offset, length = int(page['offset']), int(page['length'])\n",
    "offset_end = offset + length - 1\n",
    "# We'll get the file via HTTPS so we don't need to worry about S3 credentials\n",
    "# Getting the file on S3 is equivalent however - you can request a Range\n",
    "prefix = 'https://aws-publicdatasets.s3.amazonaws.com/'\n",
    "# We can then use the Range header to ask for just this set of bytes\n",
    "resp = requests.get(prefix + page['filename'], headers={'Range': 'bytes={}-{}'.format(offset, offset_end)})\n",
    "\n",
    "# The page is stored compressed (gzip) to save space\n",
    "# We can extract it using the GZIP library\n",
    "#raw_data = json.loads(resp.content.decode(\"utf-8\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bytes' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [34]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m raw_data \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m f \u001B[38;5;241m=\u001B[39m gzip\u001B[38;5;241m.\u001B[39mGzipFile(fileobj\u001B[38;5;241m=\u001B[39mraw_data)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# What we have now is just the WARC response, formatted:\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py:293\u001B[0m, in \u001B[0;36mload\u001B[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(fp, \u001B[38;5;241m*\u001B[39m, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    275\u001B[0m         parse_int\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_constant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_pairs_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;124;03m    a JSON document) to a Python object.\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001B[39;00m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loads(\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m(),\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcls\u001B[39m, object_hook\u001B[38;5;241m=\u001B[39mobject_hook,\n\u001B[1;32m    295\u001B[0m         parse_float\u001B[38;5;241m=\u001B[39mparse_float, parse_int\u001B[38;5;241m=\u001B[39mparse_int,\n\u001B[1;32m    296\u001B[0m         parse_constant\u001B[38;5;241m=\u001B[39mparse_constant, object_pairs_hook\u001B[38;5;241m=\u001B[39mobject_pairs_hook, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'bytes' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "raw_data = json.load(resp.content)\n",
    "f = gzip.GzipFile(fileobj=raw_data)\n",
    "\n",
    "# What we have now is just the WARC response, formatted:\n",
    "data = f.read()\n",
    "warc, header, response = data.strip().split('\\r\\n\\r\\n', 2)\n",
    "#\n",
    "# print 'WARC headers'\n",
    "# print '---'\n",
    "# print warc[:100]\n",
    "# print '---'\n",
    "# print 'HTTP headers'\n",
    "# print '---'\n",
    "# print header[:100]\n",
    "# print '---'\n",
    "# print 'HTTP response'\n",
    "# print '---'\n",
    "# print response[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Trying target domain: theguardian.com\n",
      "[*] Trying index 2014-52\n",
      "[*] Added 14287 results.\n",
      "[*] Trying index 2015-06\n",
      "[*] Added 12169 results.\n",
      "[*] Trying index 2015-11\n",
      "[*] Trying index 2015-14\n",
      "[*] Added 14327 results.\n",
      "[*] Trying index 2015-18\n",
      "[*] Added 12263 results.\n",
      "[*] Trying index 2015-22\n",
      "[*] Added 14573 results.\n",
      "[*] Trying index 2015-27\n",
      "[*] Added 12686 results.\n",
      "[*] Found a total of 80305 hits.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import argparse\n",
    "import time\n",
    "import json\n",
    "#import StringIO\n",
    "from io import StringIO\n",
    "import gzip\n",
    "import csv\n",
    "import codecs\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "#sys.setdefaultencoding('utf8')\n",
    "\n",
    "# parse the command line arguments\n",
    "#ap = argparse.ArgumentParser()\n",
    "#ap.add_argument(\"-d\",\"--domain\",required=True,help=\"The domain to target ie. cnn.com\")\n",
    "#args = vars(ap.parse_args())\n",
    "\n",
    "# https://commoncrawl.github.io/cc-crawl-statistics/plots/domains\n",
    "#domain = args['domain']\n",
    "domain = \"theguardian.com\"\n",
    "\n",
    "# list of available indices\n",
    "index_list = [\"2014-52\",\"2015-06\",\"2015-11\",\"2015-14\",\"2015-18\",\"2015-22\",\"2015-27\"]\n",
    "\n",
    "def search_domain(domain):\n",
    "\n",
    "    record_list = []\n",
    "\n",
    "    print(\"[*] Trying target domain: %s\" % domain)\n",
    "\n",
    "    for index in index_list:\n",
    "\n",
    "        print(\"[*] Trying index %s\" % index)\n",
    "\n",
    "        cc_url  = \"http://index.commoncrawl.org/CC-MAIN-%s-index?\" % index\n",
    "        cc_url += \"url=%s&matchType=domain&output=json\" % domain\n",
    "\n",
    "        response = requests.get(cc_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            records = response.content.splitlines()\n",
    "\n",
    "            for record in records:\n",
    "                record_list.append(json.loads(record))\n",
    "\n",
    "            print(\"[*] Added %d results.\" % len(records))\n",
    "\n",
    "\n",
    "    print(\"[*] Found a total of %d hits.\" % len(record_list))\n",
    "\n",
    "    return record_list\n",
    "\n",
    "results = search_domain(domain)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "'http://www.theguardian.com/accenture-partner-zone/analytics-in-action-breakthroughs-barriers-roi'"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][\"url\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71fed16058a84dc29d4b589498ef16bf"
      },
      "application/json": {
       "n": 0,
       "total": 10,
       "elapsed": 0.011595010757446289,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "can't concat str to bytes",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [133]\u001B[0m, in \u001B[0;36m<cell line: 38>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28mlen\u001B[39m(sample)), position\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m sample:\n\u001B[0;32m---> 40\u001B[0m         html_content \u001B[38;5;241m=\u001B[39m \u001B[43mdownload_page\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[*] Retrieved \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m bytes for \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mlen\u001B[39m(html_content),record[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murl\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[1;32m     43\u001B[0m         \u001B[38;5;66;03m#link_list = extract_external_links(html_content,link_list)\u001B[39;00m\n",
      "Input \u001B[0;32mIn [133]\u001B[0m, in \u001B[0;36mdownload_page\u001B[0;34m(record)\u001B[0m\n\u001B[1;32m     17\u001B[0m f \u001B[38;5;241m=\u001B[39m gzip\u001B[38;5;241m.\u001B[39mGzipFile(fileobj\u001B[38;5;241m=\u001B[39m(raw_data))\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# What we have now is just the WARC response, formatted:\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     25\u001B[0m response\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/gzip.py:300\u001B[0m, in \u001B[0;36mGzipFile.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    298\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01merrno\u001B[39;00m\n\u001B[1;32m    299\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(errno\u001B[38;5;241m.\u001B[39mEBADF, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mread() on write-only GzipFile object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 300\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/gzip.py:487\u001B[0m, in \u001B[0;36m_GzipReader.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m    483\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_new_member:\n\u001B[1;32m    484\u001B[0m     \u001B[38;5;66;03m# If the _new_member flag is set, we have to\u001B[39;00m\n\u001B[1;32m    485\u001B[0m     \u001B[38;5;66;03m# jump to the next member, if there is one.\u001B[39;00m\n\u001B[1;32m    486\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_read()\n\u001B[0;32m--> 487\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_gzip_header\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m    488\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pos\n\u001B[1;32m    489\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/gzip.py:430\u001B[0m, in \u001B[0;36m_GzipReader._read_gzip_header\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    429\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_gzip_header\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 430\u001B[0m     magic \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    431\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m magic \u001B[38;5;241m==\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    432\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/gzip.py:95\u001B[0m, in \u001B[0;36m_PaddedFile.read\u001B[0;34m(self, size)\u001B[0m\n\u001B[1;32m     93\u001B[0m read \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 95\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_buffer\u001B[49m\u001B[43m[\u001B[49m\u001B[43mread\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m     96\u001B[0m \u001B[43m       \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_length\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: can't concat str to bytes"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def download_page(record):\n",
    "\n",
    "    offset, length = int(record['offset']), int(record['length'])\n",
    "    offset_end = offset + length - 1\n",
    "\n",
    "    # We'll get the file via HTTPS so we don't need to worry about S3 credentials\n",
    "    # Getting the file on S3 is equivalent however - you can request a Range\n",
    "    prefix = 'https://aws-publicdatasets.s3.amazonaws.com/'\n",
    "\n",
    "    # We can then use the Range header to ask for just this set of bytes\n",
    "    resp = requests.get(prefix + record['filename'], headers={'Range': 'bytes={}-{}'.format(offset, offset_end)})\n",
    "\n",
    "    import io\n",
    "    raw_data = io.StringIO(resp.content.decode(\"utf-8\"))\n",
    "    f = gzip.GzipFile(fileobj=(raw_data))\n",
    "\n",
    "\n",
    "    # What we have now is just the WARC response, formatted:\n",
    "\n",
    "    data = f.read()\n",
    "\n",
    "    response = \"\"\n",
    "    response.decode(\"utf-8\")\n",
    "\n",
    "    if len(data):\n",
    "        try:\n",
    "            warc, header, response = data.strip().split('\\r\\n\\r\\n', 2)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "\n",
    "sample = results[0:10]\n",
    "with tqdm(total=(len(sample)), position=0, leave=True) as pbar:\n",
    "    for record in sample:\n",
    "        html_content = download_page(record)\n",
    "        print(\"[*] Retrieved %d bytes for %s\" % (len(html_content),record['url']))\n",
    "\n",
    "        #link_list = extract_external_links(html_content,link_list)\n",
    "\n",
    "        pbar.update()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "''"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [94]\u001B[0m, in \u001B[0;36m<cell line: 27>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     25\u001B[0m link_list   \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m results:\n\u001B[0;32m---> 29\u001B[0m     html_content \u001B[38;5;241m=\u001B[39m \u001B[43mdownload_page\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecord\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m[*] Retrieved \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m bytes for \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mlen\u001B[39m(html_content),record[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124murl\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[1;32m     33\u001B[0m     link_list \u001B[38;5;241m=\u001B[39m extract_external_links(html_content,link_list)\n",
      "Input \u001B[0;32mIn [93]\u001B[0m, in \u001B[0;36mdownload_page\u001B[0;34m(record)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mio\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# print(resp.content)\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# print(type(resp.content))\u001B[39;00m\n\u001B[0;32m---> 21\u001B[0m raw_data \u001B[38;5;241m=\u001B[39m \u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m f \u001B[38;5;241m=\u001B[39m gzip\u001B[38;5;241m.\u001B[39mGzipFile(fileobj\u001B[38;5;241m=\u001B[39mraw_data)\n\u001B[1;32m     23\u001B[0m f\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/json/__init__.py:293\u001B[0m, in \u001B[0;36mload\u001B[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(fp, \u001B[38;5;241m*\u001B[39m, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_float\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    275\u001B[0m         parse_int\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, parse_constant\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, object_pairs_hook\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw):\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;124;03m    a JSON document) to a Python object.\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001B[39;00m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 293\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loads(\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m(),\n\u001B[1;32m    294\u001B[0m         \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mcls\u001B[39m, object_hook\u001B[38;5;241m=\u001B[39mobject_hook,\n\u001B[1;32m    295\u001B[0m         parse_float\u001B[38;5;241m=\u001B[39mparse_float, parse_int\u001B[38;5;241m=\u001B[39mparse_int,\n\u001B[1;32m    296\u001B[0m         parse_constant\u001B[38;5;241m=\u001B[39mparse_constant, object_pairs_hook\u001B[38;5;241m=\u001B[39mobject_pairs_hook, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "# Downloads a page from Common Crawl - adapted graciously from @Smerity - thanks man!\n",
    "# https://gist.github.com/Smerity/56bc6f21a8adec920ebf\n",
    "\n",
    "def extract_external_links(html_content,link_list):\n",
    "\n",
    "    parser = BeautifulSoup(html_content)\n",
    "\n",
    "    links = parser.find_all(\"a\")\n",
    "\n",
    "    if links:\n",
    "\n",
    "        for link in links:\n",
    "            href = link.attrs.get(\"href\")\n",
    "\n",
    "            if href is not None:\n",
    "\n",
    "                if domain not in href:\n",
    "                    if href not in link_list and href.startswith(\"http\"):\n",
    "                        print(\"[*] Discovered external link: %s\" % href)\n",
    "                        link_list.append(href)\n",
    "\n",
    "    return link_list\n",
    "\n",
    "#record_list = search_domain(domain)\n",
    "link_list   = []\n",
    "\n",
    "for record in results:\n",
    "\n",
    "    html_content = download_page(record)\n",
    "\n",
    "    print(\"[*] Retrieved %d bytes for %s\" % (len(html_content),record['url']))\n",
    "\n",
    "    link_list = extract_external_links(html_content,link_list)\n",
    "\n",
    "\n",
    "print(\"[*] Total external links discovered: %d\" % len(link_list))\n",
    "\n",
    "with codecs.open(\"%s-links.csv\" % domain,\"wb\",encoding=\"utf-8\") as output:\n",
    "\n",
    "    fields = [\"URL\"]\n",
    "\n",
    "    logger = csv.DictWriter(output,fieldnames=fields)\n",
    "    logger.writeheader()\n",
    "\n",
    "    for link in link_list:\n",
    "        logger.writerow({\"URL\":link})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}