{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### TODOs ###\n",
    "\n",
    "# TODOs: Mine Args\n",
    "# TODO: Enhance Stance Module; Determine stance over entire argument. Only implicate stance for Noun\n",
    "# TODOs: Mine Counters\n",
    "# TODOs: Add Concepts\n",
    "# TODOs: Commonsense Query and Concept Expansion: Topics, Concepts, Synonyms\n",
    "# TODOs: Parallel process\n",
    "# TODOs: Prior tokenization and sentence segmentation to speed processing\n",
    "# TODOs: Domain Restrict. Polarising social and political debate (Class labelling) only for higher-quality argument-knowledge set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODOs: Adu, Counter + KP Extraction as 'Argument Mining' preprocessing module\n",
    "# TODOs: Implement Query Expansion at Query-time\n",
    "# TODOs: Manage Duplicate Keywords\n",
    "# DONE: Sentential Ranking\n",
    "# DONE: Include Topic Label\n",
    "# DONE: Include Concept Label\n",
    "# DONE: Add News\n",
    "# TODOs: Targeted Retreival with Semantic Graphs\n",
    "# TODOs: Target Argumentative Content Only\n",
    "# TODOs: Targeted Argument Content: Adus + Extractive Summary\n",
    "# TODOs: Query Expansion\n",
    "# TODOs: Multi-Field Search\n",
    "# TODOs: Additional News and Knowledge Sources"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "### INIT LOGGING ###\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(\"ARGUMENT-EXTRACTOR\")\n",
    "\n",
    "### NLP FUNCTIONS ###\n",
    "from src.utils_.utils import tokeniser, sentences_segment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "### LOAD DATASETS ###\n",
    "import json\n",
    "import random\n",
    "\n",
    "args = [json.loads(ln) for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "topics = [json.loads(ln) for ln in open(\"../data/argument_topic_concept.jsonl\")]\n",
    "concepts = [json.loads(ln) for ln in open(\"../data/argument_concept.jsonl\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "(5990, 5990, 10303)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topics), len(concepts), len(args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blanks  t3_3cm6jy\n",
      "blanks  t3_1egv4k\n",
      "blanks  t3_1egv4k\n",
      "blanks  t3_5wjdve\n"
     ]
    }
   ],
   "source": [
    "### ASSERT BLANKS ###\n",
    "args_ = [json.loads(ln)[\"argument\"][\"argument\"] for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "ids = [json.loads(ln)[\"id\"] for ln in open(\"../data/cmv_processed.jsonl\")]\n",
    "\n",
    "for j, k in zip(args_, ids):\n",
    "    if j == \"\":\n",
    "        print(\"blanks\", j, k)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 \n",
      "\n",
      "us sport leagues should create minor league affiliates instead of using college as their scouting ground \n",
      "\n",
      "what i mean is to make it into the nfl or nba you essentially have to go to college. you play in high school and hope to god a college scout sees you and picks you up. you play in college and hope to god a pro scout sees you and picks you up. theres no other real way to make it into those leagues. what it does is causes a bunch of people with no desire for college to go to college for the wrong reasons. they dont care about furthering their education or anything that theyre just there in hopes a scout sees them. this seems like it would only negatively effect the education of the rest of the students as part of their classmates have no desire to be there for anything related to education.instead these leagues should have a large affiliate network of professional minor leagues they use like how the nhl does it.they have a draft once a year for everyone years old and older. if youre drafted but still want to go to college youre allowed to go to college and are considered a prospect of the team that drafted you until youre done college. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### INSPECT ARG ###\n",
    "import random\n",
    "sample = random.randint(0, 99)\n",
    "\n",
    "arg = args[sample][\"argument\"][\"argument\"]\n",
    "claim = args[sample][\"claim\"]\n",
    "\n",
    "print(sample, \"\\n\")\n",
    "print(claim, \"\\n\")\n",
    "print(arg, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:summa.preprocessing.cleaner:'pattern' package not found; tag filters are not available for English\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n",
      "INFO:KEYPHRASE_EXTRACTOR:[Test Keyphrase: ] \n",
      " ['heathrow airport', 'environmental impact', 'aviation']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brazil minimum income', 'minimum income has increasingly', 'Brazil minimum', 'increasingly been accepted', 'minimum income']\n",
      "['minimum']\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "### EXTRACTORS ###\n",
    "from src.utils_.keyphrase_extraction import yake_extract_keyphrase, summa_extract_keyphrase\n",
    "\n",
    "test = \"Brazil's minimum income has increasingly been accepted.\"\n",
    "ev_kp = yake_extract_keyphrase(test)\n",
    "ev_kp_ = summa_extract_keyphrase(test)\n",
    "\n",
    "test_2 = \" \"\n",
    "ev_kp_2 = yake_extract_keyphrase(test_2)\n",
    "ev_kp_2_ = summa_extract_keyphrase(test_2)\n",
    "\n",
    "print(ev_kp)\n",
    "print(ev_kp_)\n",
    "\n",
    "# Can Handel Blanks\n",
    "print(ev_kp_2)\n",
    "print(ev_kp_2_)\n",
    "\n",
    "### KEYBERT ###\n",
    "# from keybert import KeyBERT\n",
    "#\n",
    "# kb = KeyBERT()\n",
    "# def extract_keyphrase(doc, n_gram=3, n_kp=3, use_mmr=\"False\", use_maxsum=\"False\"):\n",
    "#     kp = kb.extract_keywords(doc, keyphrase_ngram_range=(1, 3), stop_words='english', use_mmr=True, diversity=0.5)\n",
    "#\n",
    "#     return [i[0] for i in kp]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:STANCE_CLASSIFIER:[Initialised ... ]\n",
      "INFO:STANCE_CLASSIFIER:[Test Stance ... ] \n",
      " The mutual trust and understanding you share with your partner will lead to better sex, but that's not the only reason sex can be better when you're in a relationship., PRO, better sex\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12e94cae828f4c1eb54eee4ab84bcb77"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.014354228973388672,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from src.utils_.word_net_expansion import expand_query\n",
    "\n",
    "import multiprocessing\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Disable Huggingface Logging\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "topic_ids = [json.loads(ln)[\"id\"] for ln in open(\"../data/argument_topic_concept.jsonl\")]\n",
    "concept_ids = [json.loads(ln)[\"id\"] for ln in open(\"../data/argument_concept.jsonl\")]\n",
    "\n",
    "path = \"/Users/joshua.sheppard/PycharmProjects/countaBot/src/retriever/\"\n",
    "os.chdir(path)\n",
    "from src.detection.stance_classifier import sentence_stance\n",
    "from src.detection.stance_classifier import sentence_stance, compare_stance\n",
    "\n",
    "# Where notion == topic or concept\n",
    "def get_notion(notions_ids, notions_lst, arg_id, label):\n",
    "    notion_id = notions_ids.index(arg_id)\n",
    "    notion = notions_lst[notion_id][label]\n",
    "    return str(notion) if notion else None\n",
    "\n",
    "# Extract Argument Discourse as Sentences, Keyphrases, Topics and Concepts\n",
    "def extract_adus(arg_):\n",
    "\n",
    "    id_ = arg_[\"id\"]\n",
    "    arg = arg_[\"argument\"][\"argument\"]\n",
    "\n",
    "    topic = get_notion(topic_ids, topics, id_, \"topic_label\")\n",
    "    concept = get_notion(concept_ids, concepts, id_, \"concept_label\")\n",
    "\n",
    "    adu_sents = sentences_segment(arg)\n",
    "\n",
    "    extract_adus = []\n",
    "    for _ in adu_sents:\n",
    "\n",
    "        if len(tokeniser(_)) <= 5:\n",
    "            continue\n",
    "\n",
    "        #kp = extract_keyphrase(_)\n",
    "        kp = yake_extract_keyphrase(_)\n",
    "\n",
    "        aspect = \" \" if kp == [] else kp[0]\n",
    "\n",
    "        try:\n",
    "            stance = sentence_stance(_, aspect)\n",
    "        except:\n",
    "            stance = \" \"\n",
    "\n",
    "        adu = {\"sentence\": _, \"kp\": [i.lower() for i in kp], \"stance\": stance, \"aspect\": aspect, \"topic\": topic, \"concept\": concept}\n",
    "\n",
    "        extract_adus.append(adu)\n",
    "\n",
    "    claim = arg_[\"claim\"]\n",
    "    claim_kp = yake_extract_keyphrase(claim)\n",
    "    claim_adu = {\"sentence\": claim, \"kp\": [i for i in claim_kp]}\n",
    "\n",
    "    return ({\n",
    "        \"id\": id_,\n",
    "        \"claim\": claim_adu,\n",
    "        \"argument\": [i for i in extract_adus]\n",
    "    })\n",
    "\n",
    "#SAMPLE = args[0:1000]\n",
    "\n",
    "# SAMPLE = args\n",
    "# STEPS = 10\n",
    "# STEP = max(int(len(SAMPLE) / STEPS), 1)\n",
    "# BATCHES = [sample[i:i + STEP] for i in range(0, len(SAMPLE), STEP)]\n",
    "#\n",
    "# mined_args = []\n",
    "# for idx, batch in enumerate(BATCHES):\n",
    "#     print('-' * 25 + 'Batch %d/%d' % (idx + 1, len(BATCHES)) + '-' * 25)\n",
    "#\n",
    "#     with multiprocessing.Pool(8) as pool:\n",
    "#         with tqdm(total=(len(batch))) as pbar:\n",
    "#             for arg in batch:\n",
    "#                 mined_args.append(extract_adus(arg))\n",
    "#                 pbar.update()\n",
    "\n",
    "mined_args = []\n",
    "\n",
    "# sample = args\n",
    "# with tqdm(total=(len(sample)), leave=True, position=0) as pbar:\n",
    "#     for arg in sample:\n",
    "#         mined_args.append(extract_adus(arg))\n",
    "#         pbar.update()\n",
    "\n",
    "with multiprocessing.Pool(8) as pool:\n",
    "    with tqdm(total=(len(args)), position=0, leave=True) as pbar:\n",
    "        for arg in args:\n",
    "            mined_args.append(extract_adus(arg))\n",
    "            pbar.update()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10303\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'id': 't3_30oi71',\n 'claim': {'sentence': 'we should strengthen the traditional safety net rather than replace it with basic income',\n  'kp': ['strengthen the traditional safety',\n   'traditional safety net',\n   'basic income',\n   'strengthen the traditional',\n   'traditional safety']},\n 'argument': [{'sentence': 'section i why is basic income increasingly popular?',\n   'kp': ['basic income increasingly popular',\n    'income increasingly popular',\n    'basic income increasingly',\n    'increasingly popular',\n    'basic income'],\n   'stance': 'PRO',\n   'aspect': 'basic income increasingly popular',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'basic income is a policy that has broad support from both the progressive left and libertarian right.',\n   'kp': ['progressive left and libertarian',\n    'basic income',\n    'income is a policy',\n    'policy that has broad',\n    'broad support'],\n   'stance': 'PRO',\n   'aspect': 'progressive left and libertarian',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'centerleft economists including paul krugman have endorsed the scheme for various reasons.',\n   'kp': ['centerleft economists including paul',\n    'economists including paul krugman',\n    'centerleft economists including',\n    'economists including paul',\n    'including paul krugman'],\n   'stance': 'PRO',\n   'aspect': 'centerleft economists including paul',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'first bi is an effective antipoverty measure.',\n   'kp': ['effective antipoverty measure',\n    'antipoverty measure',\n    'effective antipoverty',\n    'measure',\n    'effective'],\n   'stance': 'PRO',\n   'aspect': 'effective antipoverty measure',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'bi also reduces inequality by redistributing income from capital to labor.',\n   'kp': ['reduces inequality by redistributing',\n    'inequality by redistributing income',\n    'redistributing income from capital',\n    'capital to labor',\n    'reduces inequality'],\n   'stance': 'CON',\n   'aspect': 'reduces inequality by redistributing',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'perhaps most importantly to some on the left is the notion that bi provides people with freedom.',\n   'kp': ['people with freedom',\n    'left is the notion',\n    'freedom',\n    'importantly',\n    'left'],\n   'stance': 'PRO',\n   'aspect': 'people with freedom',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'leftlibertarian political economist philippe van parijs argues that to be truly free people have to have access to the means that people need for doing what they might want to do.',\n   'kp': ['leftlibertarian political economist philippe',\n    'political economist philippe van',\n    'economist philippe van parijs',\n    'philippe van parijs argues',\n    'leftlibertarian political economist'],\n   'stance': 'PRO',\n   'aspect': 'leftlibertarian political economist philippe',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'},\n  {'sentence': 'bi provides people those means.',\n   'kp': ['people'],\n   'stance': 'NEUTRAL',\n   'aspect': 'people',\n   'topic': 'incomes policy',\n   'concept': 'increase in accumulated other comprehensive income'}]}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mined_args\n",
    "print(len(mined_args))\n",
    "\n",
    "import random\n",
    "#_ = random.randint(0, len(sample))\n",
    "example = mined_args[1]\n",
    "example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# STORE DEEP-COPY\n",
    "import copy\n",
    "mined_args_ = copy.deepcopy(mined_args)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "10303"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6c8aa8fd9a534cf5b599aeec30a8ab7b"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.015259981155395508,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### COUNTER-ARGS ###\n",
    "def extract_counters(arg_):\n",
    "    id_ = arg_[\"id\"]\n",
    "    counter = arg_[\"tgt_counter\"][\"tgt_counter\"]\n",
    "\n",
    "    counter_sents = sentences_segment(counter)\n",
    "\n",
    "    extract_counters = []\n",
    "    for _ in counter_sents:\n",
    "        if len(tokeniser(_)) <= 5:\n",
    "            continue\n",
    "\n",
    "        #kp = extract_keyphrase(_)\n",
    "        kp = yake_extract_keyphrase(_)\n",
    "\n",
    "        aspect = \" \" if kp == [] else kp[0]\n",
    "\n",
    "        try:\n",
    "            stance = sentence_stance(_, aspect)\n",
    "        except:\n",
    "            stance = \" \"\n",
    "\n",
    "        counter_unit = {\"sentence\": _, \"kp\": [i for i in kp], \"stance\": stance, \"aspect\": aspect}\n",
    "\n",
    "        extract_counters.append(counter_unit)\n",
    "\n",
    "    return ({\n",
    "        \"id\": id_,\n",
    "        \"tgt_counter\": [i for i in extract_counters]\n",
    "    })\n",
    "\n",
    "# STEPS = 10\n",
    "# STEP = max(int(len(SAMPLE) / STEPS), 1)\n",
    "# BATCHES = [sample[i:i + STEP] for i in range(0, len(SAMPLE), STEP)]\n",
    "#\n",
    "# mined_counters = []\n",
    "# for idx, batch in enumerate(BATCHES):\n",
    "#     print('-' * 25 + 'Batch %d/%d' % (idx + 1, len(BATCHES)) + '-' * 25)\n",
    "#\n",
    "#     with multiprocessing.Pool(8) as pool:\n",
    "#         with tqdm(total=(len(batch))) as pbar:\n",
    "#             for counter in batch:\n",
    "#                 mined_counters.append(extract_counters(counter))\n",
    "#                 pbar.update()\n",
    "mined_counters = []\n",
    "\n",
    "sample = args\n",
    "with multiprocessing.Pool(8) as pool:\n",
    "    with tqdm(total=(len(args)), position=0, leave=True) as pbar:\n",
    "        for arg in args:\n",
    "            mined_counters.append(extract_counters(arg))\n",
    "            pbar.update()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10303\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'id': 't3_2htk52',\n 'tgt_counter': [{'sentence': 'commercial dry dog food is full of additives preservatives rendered animal products meat not inspected as safe for humans etc.',\n   'kp': ['commercial dry dog food',\n    'additives preservatives rendered animal',\n    'preservatives rendered animal products',\n    'rendered animal products meat',\n    'commercial dry dog'],\n   'stance': 'PRO',\n   'aspect': 'commercial dry dog food'},\n  {'sentence': 'some people think dog kibble isnt even healthy for the dog some of the chemicals theyre worried about include bht and ethoxyquin.',\n   'kp': ['include bht and ethoxyquin',\n    'kibble isnt even healthy',\n    'chemicals theyre worried',\n    'theyre worried about include',\n    'worried about include bht'],\n   'stance': 'PRO',\n   'aspect': 'include bht and ethoxyquin'},\n  {'sentence': 'if the child ate one or two pieces once thats not the end of the world.',\n   'kp': ['child ate', 'end of the world', 'world', 'child', 'ate'],\n   'stance': 'NEUTRAL',\n   'aspect': 'child ate'},\n  {'sentence': 'but you cant let him help himself every time hes crawling the kitchen floor.',\n   'kp': ['crawling the kitchen floor',\n    'time hes crawling',\n    'hes crawling the kitchen',\n    'kitchen floor',\n    'time hes'],\n   'stance': 'NEUTRAL',\n   'aspect': 'crawling the kitchen floor'},\n  {'sentence': 'it only takes a second to pick the bowl up.',\n   'kp': ['pick the bowl', 'pick', 'bowl'],\n   'stance': 'NEUTRAL',\n   'aspect': 'pick the bowl'}]}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mined_args\n",
    "print(len(mined_counters))\n",
    "\n",
    "import random\n",
    "_ = random.randint(0, len(sample))\n",
    "example = mined_counters[_]\n",
    "example"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(10303, 10303)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args), len(mined_counters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import copy\n",
    "mined_counters_ = copy.deepcopy(mined_counters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(10303, 10303)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mined_args_), len(mined_counters_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joshua.sheppard/PycharmProjects/countaBot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/10303 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9323eaf487234c60ab038293a8827fa5"
      },
      "application/json": {
       "n": 0,
       "total": 10303,
       "elapsed": 0.008214950561523438,
       "ncols": null,
       "nrows": null,
       "prefix": "",
       "ascii": false,
       "unit": "it",
       "unit_scale": false,
       "rate": null,
       "bar_format": null,
       "postfix": null,
       "unit_divisor": 1000,
       "initial": 0,
       "colour": null
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ARGUMENT-EXTRACTOR:[10303 Data Stored as cmv_argument_extraction.jsonl]\n"
     ]
    }
   ],
   "source": [
    "file_name = \"cmv_argument_extraction\"\n",
    "fout = open(f\"./src/data/{file_name}.jsonl\", \"w\")\n",
    "\n",
    "# Deep_copies\n",
    "mined_args_ = copy.deepcopy(mined_args)\n",
    "mined_counters_ = copy.deepcopy(mined_counters)\n",
    "\n",
    "with tqdm(total=(len(mined_args_))) as pbar:\n",
    "    with fout:\n",
    "        for mined_arg, mined_counter in zip(mined_args_, mined_counters_):\n",
    "            # Extended pre-formatted mined object\n",
    "            # mined_arg[\"original_post\"] = original_post[\"argument\"]\n",
    "            mined_arg[\"tgt_counter\"] = [_ for _ in mined_counter[\"tgt_counter\"]]\n",
    "\n",
    "            fout.write(json.dumps(mined_arg))\n",
    "\n",
    "            fout.write(\"\\n\")\n",
    "            pbar.update()\n",
    "\n",
    "logger.info(f\"[{len(mined_args_)} Data Stored as {file_name}.jsonl]\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "### EVALUATE OUTPUT ###\n",
    "train = [json.loads(ln) for ln in open(f\"../data/{file_name}.jsonl\", \"r\")]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "10303"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3_2dqwmd \n",
      "\n",
      "[{'sentence': 'Let me start off by saying that Im a gay guy.', 'kp': ['gay guy', 'guy', 'start', 'gay'], 'stance': 'NEUTRAL', 'aspect': 'gay guy', 'topic': None, 'concept': 'gay guy'}, {'sentence': 'Im not really viewing this from the outside in though perhaps that perspective is what I need.Im nineteen years old now coming to realization with my sexuality when I had just turned thirteen years old.', 'kp': ['need.Im nineteen years', 'turned thirteen years', 'need.Im nineteen', 'coming to realization', 'turned thirteen'], 'stance': 'NEUTRAL', 'aspect': 'need.Im nineteen years', 'topic': None, 'concept': 'need.Im nineteen years'}, {'sentence': 'I was a loner who read wrote and gamed in my spare time rather than hang out with friends.', 'kp': ['loner who read', 'read wrote', 'wrote and gamed', 'spare time', 'friends'], 'stance': 'CON', 'aspect': 'loner who read', 'topic': None, 'concept': 'loner who read'}, {'sentence': 'People instantly expected me to talk with a lisp walk with a strut and love shopping.', 'kp': ['People instantly expected', 'People instantly', 'love shopping', 'instantly expected', 'lisp walk'], 'stance': 'PRO', 'aspect': 'People instantly expected', 'topic': None, 'concept': 'People instantly expected'}, {'sentence': 'People equated me to being a gay best friend on merit of that.', 'kp': ['People equated', 'gay best friend', 'friend on merit', 'People', 'equated'], 'stance': 'PRO', 'aspect': 'People equated', 'topic': None, 'concept': 'People equated'}] \n",
      "\n",
      "[{'sentence': 'Generally when you are in a discriminated against minority youve got two choices try to blend in or take ownership of the stereotype.Theres nothing wrong at all with you just being you and wanting your sexual preference to be treated no different than being left handed youre different than the majority and you do things a little differently than they do but no big deal.But the other approach is to say you think thats effeminate?', 'kp': ['left handed youre', 'discriminated against minority', 'minority youve', 'stereotype.Theres nothing wrong', 'wanting your sexual'], 'stance': 'CON', 'aspect': 'left handed youre'}, {'sentence': 'Not that I think gays are effeminate but that that was the stereotype.', 'kp': ['gays are effeminate', 'stereotype', 'gays', 'effeminate'], 'stance': 'CON', 'aspect': 'gays are effeminate'}, {'sentence': 'Im also enough that when I was young when people would say You know Bill?', 'kp': ['young when people', 'Bill', 'young', 'people'], 'stance': 'PRO', 'aspect': 'young when people'}, {'sentence': 'I just found out that hes gay they made sure to whisper the last word.', 'kp': ['hes gay', 'gay they made', 'word', 'found', 'hes'], 'stance': 'NEUTRAL', 'aspect': 'hes gay'}] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = random.randint(0, len(train))\n",
    "print(train[_][\"id\"], \"\\n\")\n",
    "print(train[_][\"argument\"], \"\\n\")\n",
    "print(train[_][\"tgt_counter\"], \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for i, j in zip(retrieved_ranked, sample):\n",
    "#     # Add counter to the dictionary (implicitly, i)\n",
    "#     i[\"counter\"] = j[\"counter\"]\n",
    "#     fout.write(json.dumps(i))\n",
    "#     fout.write(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Working Loop\n",
    "# for i in mined_counters_:\n",
    "#     test = {\n",
    "#         \"test\": [j for j in i[\"counter\"]]\n",
    "#     }"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
